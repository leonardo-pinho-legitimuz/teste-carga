âžœ kubectl logs -l app=triton-inference-server -n develop --follow --max-log-requests 10 | grep -vE 'HTTP request: 0 /(metrics|v2/health/(ready|live))|ready|GetModel|ModelStates\(\)'
  
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar
Defaulted container "triton-inference-server" out of: triton-inference-server, sidecar

I1223 07:08:22.351572 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:22.530051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:22.530081 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c00a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c0161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c0161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:22.530097 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:22.530165 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:22.530219 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:08:22.530228 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:08:22.534585214 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:22.534732893 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:22.534743897 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:22.534749426 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f56e2c00000 to 0x7f56e3400000
I1223 07:08:27.268581 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:27.441137 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:27.441169 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c00a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c013118] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c013118] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:27.441190 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:27.441259 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:27.441321 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:08:27.441334 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:08:27.446024774 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:27.446183998 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:27.446200025 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:27.446205704 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f54cec00000 to 0x7f54cf400000
I1223 07:08:34.674866 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:34.843155 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:34.843198 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:34.843222 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:34.843314 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:34.843386 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:08:34.843398 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:08:34.847274300 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:34.847415934 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:34.847428861 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:34.847434761 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f14f2c00000 to 0x7f14f3400000
I1223 07:08:37.395052 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:37.596128 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:37.596153 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c01f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c01f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:37.596167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:37.596255 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:37.596320 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:08:37.596335 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:08:37.599632291 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:37.599769690 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:37.599780665 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:37.599786780 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x68d600000 to 0x68de00000
I1223 07:08:37.624152 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:37.795844 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:37.803475 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:37.803509 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:37.803524 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:37.803628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:37.803671 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:08:37.803679 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:08:37.807502641 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:37.807638419 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:37.807705599 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:37.807729655 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3ff2c00000 to 0x7f3ff3400000
I1223 07:08:37.972325 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:37.972359 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff170017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff170017938] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:37.972379 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:37.972448 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:37.972485 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:08:37.972496 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:08:37.976822147 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:37.976969220 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:37.976980163 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:37.976985396 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff0b2c00000 to 0x7ff0b3400000
I1223 07:08:38.061645 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:38.239365 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:38.239396 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:38.239411 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:38.239486 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:38.239525 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:08:38.239533 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:08:38.243903058 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:38.244046888 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:38.244060597 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:38.244066189 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f49a2c00000 to 0x7f49a3400000
I1223 07:08:41.065623 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:41.264244 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:41.264280 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a400ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a400ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:41.264296 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:41.264399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:41.264458 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:08:41.264472 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:08:41.268565028 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:41.268751855 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:41.268765338 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:41.268771209 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x68d400000 to 0x68dc00000
I1223 07:08:43.150035 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:43.305642 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:43.305673 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0016db0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:43.305693 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:08:43.305778 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:08:43.305838 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:08:43.305848 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:08:43.310244374 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:08:43.310469674 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:08:43.310481908 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:08:43.310488617 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x68d400000 to 0x68dc00000
I1223 07:08:43.498993 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:08:43.655277 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:08:43.655311 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c0462d0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c046768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c046768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:08:43.655330 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:09:33.195672 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:33.354413 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:33.354449 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:33.354469 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:09:33.354544 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:09:33.354600 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:09:33.354609 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:09:33.359211281 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:09:33.359387201 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:09:33.359404207 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:09:33.359410515 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff09b000000 to 0x7ff09b800000
I1223 07:09:34.810798 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:35.026798 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:35.026825 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:35.026841 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:09:45.569015 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:45.742114 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:45.742141 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:45.742156 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:09:45.742327 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:09:45.742368 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:09:45.742377 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:09:45.746063385 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:09:45.746236012 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:09:45.746247945 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:09:45.746253378 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f4967200000 to 0x7f4967a00000
I1223 07:09:55.079397 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:55.256628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:55.256660 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb40161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb40161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:55.256675 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:09:55.256754 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:09:55.256785 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:09:55.256793 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:09:55.261079032 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:09:55.261211732 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:09:55.261223786 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:09:55.261229289 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3efac00000 to 0x7f3efb400000
I1223 07:09:55.734945 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:55.941024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:55.941052 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:55.941073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:09:58.968156 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:09:59.147105 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:09:59.147144 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c0491c0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c047468] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c047468] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:09:59.147164 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:01.268008 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:01.444546 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:01.444577 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c047040] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c01f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c01f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:01.444592 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:01.444660 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:10:01.444781 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:10:01.445431 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:10:01.450712606 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:10:01.450881237 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:10:01.450894664 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:10:01.450901028 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f5497200000 to 0x7f5497a00000
I1223 07:10:01.548266 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:01.748571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:01.748599 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c0476b0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:01.748618 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:04.277685 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:04.438276 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:04.438308 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff170039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff170039fc8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:04.438328 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:05.714925 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:05.883384 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:05.883417 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4047d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4046728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4046728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:05.883434 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:38.899440 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:39.134018 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:39.134055 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4049fc0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4048ba8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4048ba8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:39.134079 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:41.365584 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:41.577181 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:41.577206 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170047da0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff170018498] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff170018498] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:41.577221 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:49.306481 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:10:49.484987 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:10:49.485019 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e0400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e040161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e040161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:10:49.485035 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:10:49.485110 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:10:49.485158 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:10:49.485170 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:10:49.489290492 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:10:49.489447433 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:10:49.489459886 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:10:49.489465654 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2d52c00000 to 0x7f2d53400000

I1223 07:11:04.039680 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:04.224946 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:04.224977 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0048910] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00464e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00464e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:04.224998 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:07.960707 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:08.153768 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:08.153800 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c048b80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047e48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047e48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:08.153823 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:10.665246 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:10.825927 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:10.825965 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:10.825983 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:10.826039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:11:10.826070 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:11:10.826082 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
2024-12-23 07:11:10.829263341 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:11:10.829454156 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:11:10.829501066 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:11:10.829509625 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2d1e000000 to 0x7f2d1e800000
I1223 07:11:15.306998 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:15.436006 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:15.515549 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:15.515579 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a404c320] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a404ae18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a404ae18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:15.515598 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:15.606580 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:15.606611 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb4017408] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb4017408] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:15.606630 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:15.606696 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:11:15.606735 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:11:15.606748 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:11:15.610258689 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:14 (requested) num_bytes: 4915200 (actual) rounded_bytes:4915200
2024-12-23 07:11:15.610465268 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:11:15.610538693 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 8388608
2024-12-23 07:11:15.610562018 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3ecf200000 to 0x7f3ecfa00000
I1223 07:11:17.661411 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:17.834053 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:17.834090 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04048700] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e04046308] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e04046308] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:17.834111 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:19.225851 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:19.383954 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:19.383993 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04047980] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e040478a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e040478a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:19.384012 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:44.592942 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:44.811608 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:44.811640 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a405d940] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a405cd78] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a405cd78] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:44.811662 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:54.832156 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:54.898466 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:11:55.033851 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:55.033882 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c04aad0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c049248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c049248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:55.033897 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:11:55.058994 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:11:55.059027 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4060ef0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a405e4a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a405e4a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:11:55.059047 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:12:09.116925 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:09.314571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:09.314603 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb40469c0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb4039688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb4039688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:09.314618 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:12:17.283051 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:17.441300 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:17.441327 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb40492a0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb4047668] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb4047668] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:17.441345 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:12:24.722938 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:24.924906 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:24.924937 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004a540] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0047e18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0047e18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:24.924957 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:12:26.210490 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:26.427178 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:26.427205 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4062330] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a405f488] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a405f488] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:26.427219 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:12:28.364581 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:28.553504 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:28.553541 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4064cd0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:28.553561 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:12:35.804814 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:35.967385 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:35.967422 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e0404ab70] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e04049688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e04049688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:35.967437 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:12:36.290647 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:36.494764 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:36.494792 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a404d010] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a7d66378] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a7d66378] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:36.494811 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:12:49.056723 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:12:49.252248 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:12:49.252279 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb404ab40] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb40481d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb40481d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:12:49.252294 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:00.365267 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:00.590813 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:00.590846 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:00.590865 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:02.386263 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:02.582626 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:02.582658 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a404f320] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a404de68] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a404de68] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:02.582679 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
2024-12-23 07:13:02.703411308 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:13:02.703435190 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:02.703442689 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:02.703448941 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:02.703453843 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:02.703458265 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:02.703462231 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:02.703466667 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:02.703603224 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:02.713253894 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:02.714503652 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:02.714684589 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:13:02.714697237 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:02.714702624 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f56c7400000 to 0x7f56c7c00000
2024-12-23 07:13:02.717943863 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:02.717985317 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:02.717991978 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:02.717998369 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f56ca9e4800 to 0x7f56caae4800
I1223 07:13:02.718156 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:02.718188 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:13:02.746820 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:13:02.747370 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:02.747429 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:02.747437 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:02.747447 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 2 requests"
I1223 07:13:02.747454 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 2 requests"
I1223 07:13:02.747513 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 9830400, addr 0x7f57fc000090"
2024-12-23 07:13:06.680734469 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:13:06.680756495 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:06.680764216 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:06.680770614 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:06.680775006 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:06.680781889 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:06.680785743 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:06.680790417 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:06.680940805 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:06.690382966 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:06.691612038 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:06.691809236 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:13:06.691826471 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:06.691833008 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f54b1200000 to 0x7f54b1a00000
2024-12-23 07:13:06.695186290 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:06.695220753 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:06.695226172 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:06.695231284 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f54a6094f00 to 0x7f54a6194f00
I1223 07:13:06.695387 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:06.695417 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54a5f3cec0"
I1223 07:13:06.723317 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54a5f3cec0"
I1223 07:13:06.723356 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:06.723399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:06.723413 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:06.723420 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:06.723430 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 3 requests"
I1223 07:13:06.723437 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 3 requests"
I1223 07:13:06.723496 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 14745600, addr 0x7f55e0000090"
I1223 07:13:14.418617 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:14.631172 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:14.631199 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170059fb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff1700588f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff1700588f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:14.631218 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
2024-12-23 07:13:19.771856474 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:13:19.771883105 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:19.771890651 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:19.771896956 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:19.771901663 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:19.771906283 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:19.771910628 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:19.771915102 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:19.772065617 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:19.783853788 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:19.785409344 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:19.785602282 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:13:19.785623606 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:19.785630407 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff0af200000 to 0x7ff0afa00000
2024-12-23 07:13:19.788990189 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:19.789075791 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:19.789089621 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:19.789095352 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff09e0a2380 to 0x7ff09e1a2380
I1223 07:13:19.789275 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:19.789314 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
2024-12-23 07:13:19.822226809 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
I1223 07:13:19.824289 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:13:19.824454 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:19.824555 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:19.824571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:19.824579 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
2024-12-23 07:13:19.822254193 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:19.822261751 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:19.822268069 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:19.822272926 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:19.822277757 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:19.822281893 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:19.822286855 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:19.822452199 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:19.832083615 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:19.833452374 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:19.833618768 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
I1223 07:13:19.824590 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 3 requests"
I1223 07:13:19.824600 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 3 requests"
I1223 07:13:19.824637 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 14745600, addr 0x7ff1ce000090"
2024-12-23 07:13:19.833632807 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:19.833638863 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f4981200000 to 0x7f4981a00000
2024-12-23 07:13:19.836853105 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:19.836892437 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:19.836898059 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:19.836903065 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f495c3e3480 to 0x7f495c4e3480
I1223 07:13:19.837069 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:19.837105 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:19.864284 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:19.864339 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:19.864389 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:19.864405 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:19.864411 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:19.869006 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:19.869064 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:19.895954 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:19.895996 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:13:21.606814653 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:13:21.606841225 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:21.606848575 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:21.606854980 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:21.606859453 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:21.606864416 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:21.606868404 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:21.606872888 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:21.607026244 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:21.618719544 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:21.620367666 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:21.620547840 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:13:21.620561974 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:21.620568142 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3fd7400000 to 0x7f3fd7c00000
2024-12-23 07:13:21.623944895 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:21.624007691 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:21.624017716 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:21.624023543 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3fda991f00 to 0x7f3fdaa91f00
I1223 07:13:21.624180 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:21.624213 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f40801f7e60"
I1223 07:13:21.660948 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f40801f7e60"
I1223 07:13:21.661204 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:21.661278 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:21.661290 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:21.661298 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:21.661309 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 3 requests"
I1223 07:13:21.661318 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 3 requests"
I1223 07:13:21.661357 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 14745600, addr 0x7f410e000090"
I1223 07:13:22.052261 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
2024-12-23 07:13:22.084276718 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:13:22.084306362 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:13:22.084314110 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:13:22.084320623 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:13:22.084325464 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:13:22.084330659 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:13:22.084334833 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:13:22.084339194 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:13:22.084505230 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:13:22.096511855 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:13:22.098139534 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:22.098330865 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:13:22.098347025 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:13:22.098353893 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f14b7400000 to 0x7f14b7c00000
2024-12-23 07:13:22.101715900 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:13:22.101771800 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:13:22.101784539 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:13:22.101790609 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f14c29a29c0 to 0x7f14c2aa29c0
I1223 07:13:22.101948 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:22.101981 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14c9e94290"
I1223 07:13:22.138912 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14c9e94290"
I1223 07:13:22.138978 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:22.139036 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139058 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139066 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139080 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139086 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139093 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139099 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139106 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:22.139117 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 10 requests"
I1223 07:13:22.139125 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 10 requests"
I1223 07:13:22.139212 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 49152000, addr 0x7f1604000090"
I1223 07:13:22.246183 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:22.246216 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c00a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c04b848] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c04b848] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:22.246231 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:30.870764 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:31.026506 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:31.026532 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dcf40] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c013118] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c013118] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:31.026551 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:38.732601 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:38.892448 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:38.892473 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:38.892488 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:38.892589 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:38.892872 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:38.893371 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:38.898030 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:38.898101 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:38.926580 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:38.926622 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:42.686630 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:42.897951 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:42.897977 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:42.898024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:42.898126 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:42.898158 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:42.898167 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:42.902514 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:42.902594 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:42.930903 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:42.930944 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:43.208526 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:43.372655 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:43.372682 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:43.372696 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:43.372771 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:43.372791 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:43.372799 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:43.379816 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:43.379927 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:43.410401 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:43.410458 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:46.208999 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:46.366865 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:46.366895 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4050168] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4050168] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:46.366914 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:13:49.818743 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:50.056871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:50.056902 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:50.056917 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:50.056995 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:50.057136 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:50.057214 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:50.062076 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:50.062152 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:50.093426 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:50.093475 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:54.009389 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:54.237030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:54.237058 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:54.237076 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:54.237146 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:54.237166 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:54.237176 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:54.241327 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:54.241414 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:54.269466 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:54.269514 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:13:55.579699 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:55.773822 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:55.773857 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4051920] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4051848] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4051848] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:55.773873 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:56.758083 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:56.936908 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:56.936937 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c0482b0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c0481d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c0481d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:56.936952 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:58.742796 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:13:58.917190 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:13:58.917216 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:13:58.917231 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:13:58.917312 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:13:58.917343 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:13:58.917352 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:13:58.923106 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:13:58.923188 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:13:58.953592 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:13:58.953635 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:04.719202 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:04.906018 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:04.906045 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:04.906059 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:04.906121 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:04.906145 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:04.906153 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:04.912855 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:04.912941 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:04.943694 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:04.943747 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:09.061876 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:09.250308 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:09.250342 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:09.250365 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:09.250434 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:09.250506 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:09.250542 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:09.256481 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:09.256565 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:09.286234 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:09.286285 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:11.028804 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:11.184660 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:11.184686 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:11.184701 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:11.184831 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:11.184856 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:11.184864 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:11.188667 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:11.188733 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:11.216455 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:11.216504 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:13.434583 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:13.588387 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:13.588425 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e0404cd00] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0404b888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0404b888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:13.588440 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:19.204610 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:19.411496 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:19.411523 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:19.411542 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:19.411687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:19.411778 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:19.411888 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:19.416160 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:19.416241 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:19.446763 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:19.446812 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:25.493094 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:25.722935 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:25.722981 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:25.723001 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:25.723065 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:25.723149 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:25.723158 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:25.728541 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:25.728625 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:25.759693 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:25.759741 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:25.815960 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:26.017765 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:26.017794 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:26.017812 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:26.017939 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:26.018130 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:26.018140 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:26.022513 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:26.022589 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:26.053014 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:26.053059 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:28.116641 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:28.295024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:28.295050 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dee10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557d7dd708] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557d7dd708] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:28.295069 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:30.857847 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:31.064855 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:31.064886 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:31.064905 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:31.064984 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:31.065006 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:31.065014 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:31.069363 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:31.069444 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:31.099335 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:31.099382 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:14:38.573595616 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:14:38.573623478 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:14:38.573631188 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:14:38.573637129 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:14:38.573641776 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:14:38.573646775 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:14:38.573650810 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:14:38.573655358 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:14:38.573836546 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:14:38.585711214 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:14:38.587343189 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:14:38.587526962 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:14:38.587548495 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:14:38.587555261 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3ee9200000 to 0x7f3ee9a00000
2024-12-23 07:14:38.590847072 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:14:38.590908130 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:14:38.590922723 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:14:38.590928514 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3ede9d5c40 to 0x7f3edead5c40
I1223 07:14:38.591090 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:38.591124 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3ee1e37b00"
I1223 07:14:38.628006 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3ee1e37b00"
I1223 07:14:38.628082 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:38.628140 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:38.628156 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:38.628163 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:38.628174 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 3 requests"
I1223 07:14:38.628181 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 3 requests"
I1223 07:14:38.628260 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 14745600, addr 0x7f400c000090"
I1223 07:14:40.748717 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:40.931531 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:40.931558 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:40.931577 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:40.931674 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:40.932335 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:40.932356 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:40.936710 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:40.936785 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:40.969808 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:40.969855 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:43.156403 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:43.354002 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:43.354031 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4053910] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a40525a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a40525a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:43.354050 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:43.718857 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:43.903844 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:43.903875 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:43.903893 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:43.903962 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:43.904067 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:43.904083 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:43.908444 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:43.908525 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:43.942711 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:43.943086 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:47.871972 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:48.076530 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:48.076554 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:48.076569 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:48.076638 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:48.076752 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:48.076812 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:48.082746 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:48.082835 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:48.113900 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:48.113953 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:49.926625 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:50.087514 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:50.087544 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:50.087563 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:50.087635 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:50.087665 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:50.087674 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:50.094150 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:50.094256 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:50.124605 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:50.124656 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:58.034263 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:58.232799 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:58.232828 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:58.232847 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:58.232913 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:58.232943 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:58.232954 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:58.238393 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:58.238476 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:58.268756 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:58.268813 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:14:59.025015 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:14:59.204668 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:14:59.204693 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:14:59.204713 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:14:59.204767 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:14:59.204786 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:14:59.204794 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:14:59.209727 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:14:59.209826 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:14:59.239895 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:14:59.239945 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:01.413069 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:01.615393 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:01.615423 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c00a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c0161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c0161c8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:01.615442 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"

I1223 07:15:06.935247 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:07.129138 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:07.129170 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:07.129192 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:07.129249 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:07.129276 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:07.129293 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:07.135062 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:07.135144 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:07.165393 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:07.165442 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:09.902877 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:10.124844 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:10.124874 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:10.124892 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:10.124982 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:10.125419 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:10.125625 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:10.130192 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:10.130273 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:10.164251 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:10.164303 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:10.294856 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:10.295483 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:10.501116 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:10.501142 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7e10e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557d7dfba8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557d7dfba8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:10.501161 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:10.510575 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:10.510607 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:10.510628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:10.512416 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:10.512451 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:10.512460 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:10.517673 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:10.517862 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:10.552797 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:10.552871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:17.693131 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:17.897306 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:17.897334 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:17.897354 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:17.897414 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:17.897467 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:17.897529 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:17.902532 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:17.902611 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:17.934152 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:17.934203 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:19.768596 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:19.981523 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:19.981551 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:19.981574 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:19.981643 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:19.981665 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:19.981673 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:19.985783 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:19.985855 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:20.018896 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:20.018953 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:23.689747 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:23.902129 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:23.902156 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:23.902174 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:23.902234 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:23.902257 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:23.902270 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:23.906604 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:23.906691 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:23.938004 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:23.938047 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:26.047140 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:26.252435 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:26.252465 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54046318] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:26.252485 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:26.252543 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:26.252571 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:26.252585 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:26.256942 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:26.257023 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:26.289026 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:26.289589 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:32.468887 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:32.681877 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:32.681907 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:32.681926 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:32.681993 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:32.682055 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:32.682093 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:32.686399 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:32.686480 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:32.719227 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:32.719275 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:15:33.606204710 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:33.606226442 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:33.606232158 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:33.606236703 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:33.606240295 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:33.606243876 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:33.606247939 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:33.606252827 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:33.606445040 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:33.617654162 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:33.654141722 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:33.654381649 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:33.654403399 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:33.654411126 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f56dd600000 to 0x7f56dde00000
2024-12-23 07:15:33.656985904 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:33.657024878 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:33.657030642 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:33.657035861 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f578183e080 to 0x7f578193e080
I1223 07:15:33.657192 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:33.657223 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5781698c50"
I1223 07:15:33.686320 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5781698c50"
I1223 07:15:33.686371 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:33.686416 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:33.686426 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:33.686436 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 2 requests"
I1223 07:15:33.686448 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 2 requests"
I1223 07:15:33.686485 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 9830400, addr 0x7f57fc9600a0"
I1223 07:15:33.732826 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:33.962446 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:33.962470 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7e32e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557d7e1bd8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557d7e1bd8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:33.962490 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:34.010413 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:34.197400 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:34.197424 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:34.197443 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:34.197524 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:34.197586 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:34.197599 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:34.203862 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:34.203954 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:34.235990 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:34.236052 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:36.277290 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:36.474115 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:36.474147 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54046730] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:36.474167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:36.475332 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:36.475474 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:36.475557 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:36.480745 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:36.480849 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:36.512038 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:36.512306 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:37.794333 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
2024-12-23 07:15:37.982151949 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:37.982171854 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:37.982178574 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:37.982183644 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:37.982187445 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:37.982191022 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:37.982194328 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:37.982197906 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:37.982391709 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
I1223 07:15:37.989203 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:37.989225 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:37.989240 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:37.989297 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:37.989318 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:37.989330 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
2024-12-23 07:15:37.993640885 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:15:37.995456 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
2024-12-23 07:15:38.031882949 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:38.032061211 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:38.032075842 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:38.032082312 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f54afc00000 to 0x7f54b0400000
2024-12-23 07:15:38.034584123 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:38.034615788 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:38.034622225 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:38.034628103 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f547e12f580 to 0x7f547e22f580
I1223 07:15:38.034783 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:38.034816 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555da40e10"
I1223 07:15:38.071152 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555da40e10"
I1223 07:15:38.071209 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:38.071279 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:38.071294 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:38.071301 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:38.071309 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:38.071320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:38.071330 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 5 requests"
I1223 07:15:38.071341 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 5 requests"
I1223 07:15:38.071392 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 24576000, addr 0x7f55e0e100a0"
I1223 07:15:37.995543 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:38.025104 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:38.025173 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:15:39.301511011 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:39.301534277 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:39.301541570 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:39.301547812 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:39.301552699 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:39.301558013 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:39.301561863 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:39.301566277 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:39.301731033 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:39.311472481 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:39.313014743 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:39.313198939 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:39.313214195 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:39.313219504 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2d17400000 to 0x7f2d17c00000
2024-12-23 07:15:39.316632292 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:39.316686127 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:39.316695835 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:39.316701233 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2d21a17400 to 0x7f2d21b17400
I1223 07:15:39.316865 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:39.316901 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d2a1cdc70"
I1223 07:15:39.344332 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d2a1cdc70"
I1223 07:15:39.344405 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:39.344458 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:39.344470 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:39.344476 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:39.344482 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:39.344491 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 4 requests"
I1223 07:15:39.344498 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 4 requests"
I1223 07:15:39.344591 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 19660800, addr 0x7f2e64000090"
I1223 07:15:48.696734 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:48.729347 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:48.889074 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:48.889098 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557c047040] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557d7e4218] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557d7e4218] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:48.889115 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:48.901006 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:48.901034 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:48.901054 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:48.901115 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:48.901161 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:48.901171 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:48.905701 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:48.905777 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:48.937794 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:48.937855 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:15:50.469108686 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:50.469130437 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:50.469135950 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:50.469140478 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:50.469143994 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:50.469147602 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:50.469150771 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:50.469154145 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:50.469339403 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:50.480492524 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:50.573122295 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:50.573307184 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:50.573323337 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:50.573327579 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff0aca00000 to 0x7ff0ad200000
2024-12-23 07:15:50.576085278 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:50.576114450 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:50.576120723 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:50.576126316 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7ff149094a80 to 0x7ff149194a80
I1223 07:15:50.576293 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:50.576329 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:15:50.604860 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:15:50.584813 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:50.604914 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:50.787117 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:50.787143 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04b5a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04b5a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:50.787158 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:51.589465 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:51.737064 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:51.737090 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54017888] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:51.737108 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:51.737170 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:51.737220 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:51.737268 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:51.741815 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:51.741884 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:51.769205 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:51.769258 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:51.963151 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:52.138775 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:52.138798 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004ada8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004ada8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:52.138812 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
2024-12-23 07:15:52.316221525 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:52.316243410 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:52.316249535 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:52.316254223 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:52.316258057 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:52.316262986 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:52.316267737 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:52.316273157 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:52.316448766 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:52.327198323 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:52.382870699 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:52.383103400 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:52.383118727 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:52.383124868 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f4987200000 to 0x7f4987a00000
2024-12-23 07:15:52.385667525 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:52.385691923 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:52.385695882 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:52.385699604 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f494c000040 to 0x7f494c100040
I1223 07:15:52.385860 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:52.385890 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:15:52.413779 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:15:52.413828 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:15:53.831405690 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:53.831431030 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:53.831438357 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:53.831444199 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:53.831449714 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:53.831454422 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:53.831458442 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:53.831462702 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:53.831647066 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:53.844909615 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:53.882213988 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:53.882426604 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:53.882442002 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:53.882447415 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3fed600000 to 0x7f3fede00000
2024-12-23 07:15:53.885001777 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:53.885038008 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:53.885044110 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:53.885049898 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f408bb60180 to 0x7f408bc60180
I1223 07:15:53.885208 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:53.885245 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:15:53.913398 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:15:53.913449 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:53.913493 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:53.913509 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:53.913516 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:53.917318 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:53.917365 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:15:53.977267 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:15:53.977326 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:55.335474 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:55.495324 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:55.495356 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:55.495375 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:55.495454 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:55.495490 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:55.495500 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:55.502286 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:55.502356 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:15:55.529406 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:15:55.529457 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:15:55.632279742 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:15:55.632301826 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:15:55.632308429 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:15:55.632313360 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:15:55.632317225 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:15:55.632320981 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:15:55.632324616 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:15:55.632329350 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:15:55.632534320 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:15:55.644077949 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:15:55.716112294 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:55.716297949 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:15:55.716310890 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:15:55.716316318 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f14cf600000 to 0x7f14cfe00000
2024-12-23 07:15:55.718987515 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:15:55.719016728 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:15:55.719021146 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:15:55.719024872 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f1589094c80 to 0x7f1589194c80
I1223 07:15:55.719429 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:55.719498 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f158940dd10"
I1223 07:15:55.751730 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f158940dd10"
I1223 07:15:55.751794 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:15:55.751868 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:55.751884 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:55.751891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:55.751902 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 3 requests"
I1223 07:15:55.751910 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 3 requests"
I1223 07:15:55.751957 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 14745600, addr 0x7f1606ee00a0"
I1223 07:15:59.420186 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:15:59.572142 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:15:59.572178 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:15:59.572202 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:15:59.572345 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:15:59.572373 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:15:59.572384 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:15:59.577537 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:15:59.577597 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:15:59.612096 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:15:59.612147 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:09.664587 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:09.819776 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:09.819805 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:09.819821 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:09.819968 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:09.819999 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:16:09.820007 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:16:09.827057 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:09.827100 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:16:09.855113 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:16:09.855167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:10.240291 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:10.389485 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:10.389512 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:10.389527 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:10.389619 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:10.389660 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:10.389674 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:10.394452 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:10.394510 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:10.423519 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:10.423575 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:11.255693 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:11.409805 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:11.409829 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c04cf50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04b6a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04b6a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:11.409843 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:12.285178 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:12.457158 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:12.457186 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:12.457204 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:12.457289 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:12.457310 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:12.457318 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:12.461603 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:12.461647 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:12.490167 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:12.490220 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:12.933178 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:13.076867 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:13.076901 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:13.076916 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:13.076994 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:13.077027 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:13.077038 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:13.083815 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:13.083897 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:16:13.110919 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:16:13.110969 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:20.675590 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:20.830928 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:20.830958 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:20.830973 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:20.831044 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:20.831100 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:16:20.831111 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:16:20.837878 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:20.838025 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:16:20.865927 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:16:20.865973 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:25.711158 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:25.875123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:25.875153 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:25.875174 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:25.875244 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:25.875300 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:25.875466 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:25.880479 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:25.880524 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:25.909094 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:25.909149 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:28.077303 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:28.232605 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:28.232636 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:28.232650 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:28.232716 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:28.232750 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:28.232759 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:28.233462 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:28.239665 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:28.239736 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:16:28.266860 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:16:28.266908 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:28.392332 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:28.392366 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:28.392381 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:28.392504 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:28.392538 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:16:28.392547 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:16:28.399395 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:28.399436 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:16:28.426972 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:16:28.427036 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:29.999947 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:30.147406 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:30.147432 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0008d50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b000ea88] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:30.147447 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:30.147507 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:30.147731 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:30.147816 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:30.152968 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:30.153023 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:30.187513 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:30.187567 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:31.300525 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:31.479985 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:31.480011 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b0016db0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004a328] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004a328] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:31.480029 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:31.480101 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:31.480120 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:31.480129 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:31.485000 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:31.485064 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:31.516657 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:31.516814 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:35.376262 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:35.529323 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:35.529351 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004afb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:35.529370 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:35.529509 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:35.529718 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:35.529848 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:35.534143 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:35.534192 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:35.563380 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:35.563426 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:39.983169 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:40.145678 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:40.145703 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004afb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:40.145719 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:40.145791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:40.145842 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:40.145851 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:40.150388 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:40.150432 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:40.179230 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:40.179326 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:44.585063 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:44.807391 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:44.807424 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004c410] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0004a48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0004a48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:44.807439 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:44.807581 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:44.807604 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:44.807611 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:44.811715 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:44.811763 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:44.845286 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:44.845347 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:47.281460 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:47.438242 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:47.438274 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:47.438289 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:47.438358 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:47.438383 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:47.438391 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:47.445604 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:47.445700 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:16:47.472937 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:16:47.473027 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:48.610561 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:48.791601 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:48.791630 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004c410] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0004a48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0004a48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:48.791648 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:48.791720 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:48.791793 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:48.791839 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:48.796198 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:48.796257 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:16:48.824074 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:16:48.824387 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:48.926321 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:49.070943 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:49.070975 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:49.070989 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:49.071068 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:49.071144 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:16:49.071153 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:16:49.077979 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:49.078023 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:16:49.105516 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:16:49.105572 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:53.871032 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:54.027681 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:54.027714 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:54.027729 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:54.027807 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:54.027840 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:16:54.027877 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:16:54.034688 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:54.034769 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:16:54.062155 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:16:54.062216 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:16:55.024200 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:16:55.168637 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:16:55.168669 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:16:55.168687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:16:55.168751 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:16:55.168773 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:16:55.168780 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:16:55.175478 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:16:55.175528 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:16:55.202838 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:16:55.202891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:00.029518 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:00.185276 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:00.185310 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:00.185325 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:00.185402 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:00.185439 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:00.185449 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:00.192301 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:00.192384 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:00.219453 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:00.219507 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:02.635620 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:02.799332 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:02.799365 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:02.799390 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:02.799487 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:02.799570 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:02.799596 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:02.806521 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:02.806571 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:02.836779 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:02.836838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:07.907375 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:07.983633 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:08.070644 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:08.070675 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:08.070691 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:08.070791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:08.070819 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:08.070830 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:08.077947 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:08.077996 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:08.105881 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:08.105938 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:08.128532 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:08.128564 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:08.128579 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:08.128688 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:08.128715 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:08.128724 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:08.132870 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:08.132914 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:08.160957 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:08.161017 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:08.267669 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:08.412200 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:08.412233 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:08.412248 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:08.412336 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:08.412372 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:08.412381 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:08.419213 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:08.419299 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:08.446289 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:08.446361 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:10.585269 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:10.730414 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:10.730446 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:10.730461 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:10.730520 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:10.730539 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:10.730548 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:10.736715 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:10.736762 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:10.764781 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:10.764838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:17:10.831870807 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:17:10.831896293 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:17:10.831904790 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:17:10.831911168 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:17:10.831916591 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:17:10.831922868 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:17:10.831927487 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:17:10.831933156 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:17:10.832123079 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:17:10.843477212 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:17:10.880894197 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:17:10.881087518 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:17:10.881103864 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:17:10.881109844 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3ee7c00000 to 0x7f3ee8400000
2024-12-23 07:17:10.883549164 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:17:10.883579880 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:17:10.883586103 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:17:10.883591627 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f3f8843d040 to 0x7f3f8853d040
I1223 07:17:10.883758 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:10.883792 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:17:10.915513 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:17:10.915616 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:12.211869 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:12.367574 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:12.367605 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:12.367619 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:12.367683 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:12.367706 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:12.367712 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:12.374466 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:12.374516 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:12.401919 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:12.401958 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:16.830096 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:16.985772 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:16.985804 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:16.985818 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:16.985890 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:16.985909 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:16.985917 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:16.992681 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:16.992765 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:17.019816 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:17.019873 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:18.742473 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:18.887961 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:18.887981 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:18.887995 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:18.888377 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:18.888493 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:18.888563 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:18.894681 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:18.894740 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:18.931428 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:18.931511 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:27.614166 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:27.768383 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:27.768410 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:27.768425 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:27.768491 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:27.768515 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:27.768527 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:27.786816 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:27.786873 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:27.816810 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:27.816863 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:29.096726 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:29.252685 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:29.252718 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:29.252733 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:29.252810 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:29.252851 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:29.252860 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:29.259617 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:29.259667 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:29.287084 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:29.287153 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:32.022792 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:32.179308 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:32.179333 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:32.179348 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:32.179479 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:32.179506 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:32.179516 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:32.188513 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:32.188590 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:32.220619 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:32.220672 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:32.911710 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:33.084536 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:33.084568 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004bb50] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004cb18] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:33.084586 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:33.084772 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:33.084865 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:33.084902 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:33.090164 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:33.090220 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:33.122365 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:33.122438 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:34.007007 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:34.162374 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:34.162406 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:34.162420 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:34.162490 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:34.162526 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:34.162656 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:34.169875 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:34.169960 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:34.196904 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:34.196954 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:34.529966 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:34.687608 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:34.687642 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:34.687661 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:34.687733 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:34.687775 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:34.687784 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:34.694556 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:34.694606 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:34.722022 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:34.722096 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:35.647712 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:35.808798 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:35.808828 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004d1f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:35.808847 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:35.808932 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:35.808950 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:35.808958 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:35.816867 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:35.816926 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:35.846041 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:35.846098 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:36.990333 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:37.135009 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:37.135038 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:37.135055 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:37.135128 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:37.135212 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:37.135226 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:37.141999 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:37.142074 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:37.169017 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:37.169062 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:40.463377 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:40.622808 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:40.622836 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:40.622851 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:40.622934 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:40.623055 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:40.623114 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:40.629948 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:40.629995 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:40.657403 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:40.657455 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:44.361900 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:44.413993 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:44.517138 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:44.517173 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:44.517188 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:44.517296 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:44.517318 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:44.517327 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:44.524134 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:44.524212 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:44.551149 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:44.551215 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:44.605913 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:44.605947 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004d1f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004d728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004d728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:44.605962 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:44.606018 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:44.606040 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:44.606048 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:44.611501 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:44.611560 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:44.643202 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:44.643263 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:17:48.621197 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:48.776976 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:48.777011 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:48.777030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:48.777099 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:48.777118 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:17:48.777131 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:17:48.783923 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:48.783972 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:17:48.811429 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:17:48.811480 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:53.196143 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:53.398164 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:53.398190 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004d1f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004d728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004d728] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:53.398206 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:53.398271 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:53.398300 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:53.398309 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:53.403141 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:53.403189 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:53.434449 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:53.434499 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:55.030861 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:55.185665 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:55.185691 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:55.185705 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:55.185777 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:55.185795 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:55.185804 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:55.192615 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:55.192686 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:17:55.219731 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:17:55.219781 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:57.906594 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:17:58.112992 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:17:58.113028 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004cbf0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:17:58.113049 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:17:58.113123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:58.113151 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:17:58.113163 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:17:58.117935 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:58.117991 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:17:58.152054 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:17:58.152134 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:17:59.096677490 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:17:59.096704461 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:17:59.096711091 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:17:59.096717549 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:17:59.096721989 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:17:59.096727386 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:17:59.096731797 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:17:59.096736483 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 2, 2
2024-12-23 07:17:59.096976470 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:17:59.110967426 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:17:59.153814 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:59.153923 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:17:59.153992 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:59.154023 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56b1727290"
I1223 07:17:59.182911 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:17:59.217351 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56b1727290"
I1223 07:17:59.217394 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:59.217413 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:59.217442 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f57fc000090"
I1223 07:17:59.217498 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:59.217518 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:17:59.217531 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 2 requests"
I1223 07:17:59.217539 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 2 requests"
I1223 07:17:59.217571 1 pinned_memory_manager.cc:198] "pinned memory allocation: size 9830400, addr 0x7f57fc000090"
I1223 07:17:59.225807 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:59.225923 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:17:59.226007 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:17:59.226020 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56b1727290"
I1223 07:17:59.259148 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:17:59.292971 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56b1727290"
I1223 07:17:59.293031 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:59.293049 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:17:59.293069 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f57fc000090"
I1223 07:18:01.954169 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:02.109399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:02.109432 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:02.109446 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:02.109531 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:02.109572 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:02.109581 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:02.116784 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:02.116836 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:02.144866 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:02.144920 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:02.948226 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:03.146826 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:03.146853 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004cbf0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004d8f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004d8f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:03.146872 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:03.146950 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:03.147133 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:03.147234 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:03.152004 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:03.152050 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:18:03.181401 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:18:03.181448 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:18:03.511141637 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:18:03.511168534 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:18:03.511176669 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:18:03.511182681 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:18:03.511187632 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:18:03.511193421 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:18:03.511197609 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:18:03.511202053 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 3, 3
2024-12-23 07:18:03.511416624 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:18:03.525510516 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:18:03.569457 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:03.569558 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54850bbc90"
I1223 07:18:03.569624 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:03.569639 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54a5f3cec0"
I1223 07:18:03.569713 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:03.569728 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54a9e40f90"
I1223 07:18:03.612873 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54850bbc90"
I1223 07:18:03.646942 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54a5f3cec0"
I1223 07:18:03.678833 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54a9e40f90"
I1223 07:18:03.678871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:03.678891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:03.678909 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:03.678930 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f55e0000090"
I1223 07:18:03.678981 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:03.679001 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:03.679008 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:03.684579 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:03.684672 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54850bbc90"
I1223 07:18:03.717516 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54850bbc90"
I1223 07:18:03.717554 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:03.984589 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:04.140826 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:04.140858 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:04.140872 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:04.140992 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:04.141094 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:04.141135 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:04.148147 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:04.148240 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:04.175352 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:04.175402 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:04.718082 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:04.915797 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:04.915824 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004cbf0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004d8f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004d8f8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:04.915843 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:04.915912 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:04.915986 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:04.915995 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:04.920288 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:04.920339 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:18:04.954760 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:18:04.954849 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:06.849829 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:07.006143 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:07.006173 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a5400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047068] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:07.006187 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:07.006250 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:07.006278 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:07.006304 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:07.013182 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:07.013236 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:07.041453 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:07.041504 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:08.920266 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:09.091089 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:09.091115 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b0002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:09.091129 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:09.091184 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:09.091210 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:09.091218 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:09.100145 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:09.100195 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:18:09.128114 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:18:09.128160 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:09.712095 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:09.868211 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:09.868244 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047168] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047168] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:09.868265 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:09.868360 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:09.868524 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:09.868561 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:09.875578 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:09.875668 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:09.902679 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:09.902740 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:10.547877 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:10.704250 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:10.704281 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:10.704296 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:10.704363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:10.704380 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:10.704387 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:10.711196 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:10.711245 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:10.738927 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:10.738977 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:18:12.794790226 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:18:12.794817785 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:18:12.794824522 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:18:12.794830728 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:18:12.794835295 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:18:12.794840090 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:18:12.794844493 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:18:12.794849249 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 1, 1
2024-12-23 07:18:12.795030250 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:18:12.808198402 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
2024-12-23 07:18:12.847619637 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cuda. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:18:12.847821019 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 8388608 bytes.
2024-12-23 07:18:12.847837418 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 16777216
2024-12-23 07:18:12.847842844 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2d1f200000 to 0x7f2d1fa00000
2024-12-23 07:18:12.851035076 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:9 (requested) num_bytes: 201600 (actual) rounded_bytes:201728
2024-12-23 07:18:12.851076620 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 1048576 bytes.
2024-12-23 07:18:12.851083001 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 1048576
2024-12-23 07:18:12.851089041 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f2de83d7200 to 0x7f2de84d7200
I1223 07:18:12.851255 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:12.851288 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de980b720"
I1223 07:18:12.887528 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de980b720"
I1223 07:18:12.887609 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:18:15.582674782 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:18:15.582701859 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:18:15.582709345 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:18:15.582715582 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:18:15.582719931 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:18:15.582724559 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:18:15.582728722 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:18:15.582734294 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 3, 3
2024-12-23 07:18:15.582956108 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:18:15.594350177 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:18:15.695882 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:15.696006 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:18:15.696074 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:15.696090 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a60da220"
I1223 07:18:15.696185 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:15.696199 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5d464e0"
I1223 07:18:15.724358 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:18:15.752455 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a60da220"
I1223 07:18:15.780448 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5d464e0"
I1223 07:18:15.780510 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:15.783128 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:15.783157 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:15.783186 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7ff1ce000090"
I1223 07:18:16.299661 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:16.454896 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:16.454929 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:16.454944 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:16.455007 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:16.455025 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:16.455034 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:16.461767 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:16.461843 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:16.488886 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:16.488937 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:20.050783 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:20.206500 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:20.206532 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:20.206551 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:20.206624 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:20.206666 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:20.206676 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:20.213330 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:20.213373 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:20.240844 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:20.240882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:18:22.140414535 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:18:22.140437562 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:18:22.140443456 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:18:22.140448033 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:18:22.140451407 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:18:22.140454903 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:18:22.140458882 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:18:22.140464103 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 3, 3
2024-12-23 07:18:22.140669220 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:18:22.151973321 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:18:22.194006 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:22.194108 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:18:22.194176 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:22.194193 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaad1f50"
I1223 07:18:22.194250 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:22.194266 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fc43cff40"
I1223 07:18:22.222121 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:18:22.249698 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaad1f50"
I1223 07:18:22.277240 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fc43cff40"
I1223 07:18:22.277291 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:22.280030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:22.280056 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:22.280091 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f410e000090"
I1223 07:18:23.111372 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:23.267626 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:23.267655 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:23.267673 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:23.267746 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:23.267790 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:23.267801 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:23.274615 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:23.274696 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:23.301825 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:23.301878 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:18:25.581070 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:25.738898 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:25.738931 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54039688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54039688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:25.738950 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:25.739025 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:25.739049 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:25.739068 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:25.746201 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:25.746247 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:25.774249 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:25.774297 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:26.249890 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:26.395130 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:26.395164 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:26.395178 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:26.395255 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:26.395288 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:26.395305 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:26.402455 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:26.402559 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:26.429997 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:26.430052 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:26.597218 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:26.761119 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:26.761151 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:26.761166 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:26.761256 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:26.761276 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:26.761285 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:26.768120 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:26.768166 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:18:26.795966 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:18:26.796024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:28.301645 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:28.457815 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:28.457846 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:28.457861 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:28.457943 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:28.457984 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:28.457994 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:28.465155 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:28.465207 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:28.493181 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:28.493230 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:30.999739 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:31.156741 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:31.156775 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:31.156789 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:31.156867 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:31.156901 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:31.156911 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:31.163795 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:31.163897 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:31.190978 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:31.191030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:18:34.005484 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:34.161915 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:34.161946 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:34.161961 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:34.162030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:34.162058 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:34.162068 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:34.169566 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:34.169609 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:34.197591 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:34.197633 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:36.166080 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:36.322443 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:36.322476 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:36.322490 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:36.322557 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:36.322580 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:36.322589 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:36.329420 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:36.329483 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:36.356603 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:36.356658 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:40.779247 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:40.934661 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:40.934693 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:40.934708 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:40.934779 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:40.934819 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:40.934828 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:40.941684 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:40.941735 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:40.969721 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:40.969768 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:41.243445 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:41.389085 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:41.389117 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:41.389131 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:41.389211 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:41.389243 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:41.389253 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:41.396008 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:41.396091 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:41.426288 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:41.426335 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:42.882180 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:43.030320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:43.030352 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:43.030372 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:43.030442 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:43.030507 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:43.030579 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:43.038548 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:43.038665 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:18:43.066359 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:18:43.066409 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:46.328164 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:46.484743 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:46.484774 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:46.484793 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:46.484866 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:46.484890 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:46.484900 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:46.491846 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:46.491891 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:46.519468 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:46.519513 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:46.534982 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:46.698835 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:46.698867 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:46.698882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:46.698959 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:46.698980 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:46.699001 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:46.705851 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:46.705901 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:18:46.733823 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:18:46.733878 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:49.402586 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:49.557909 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:49.557939 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:49.557958 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:49.558028 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:49.558052 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:49.558062 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:49.565506 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:49.565597 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:49.592786 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:49.592837 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:51.695822 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:51.852558 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:51.852592 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:51.852607 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:51.852677 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:51.852700 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:51.852712 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:51.859924 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:51.859967 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:18:51.887414 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:18:51.887468 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:53.710271 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:53.858528 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:53.858561 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:53.858576 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:53.858653 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:53.858675 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:18:53.858684 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:18:53.866471 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:53.866576 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:18:53.894394 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:18:53.894444 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:54.150411 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:18:54.294323 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:18:54.294360 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:18:54.294379 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:18:54.294456 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:18:54.294502 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:18:54.294514 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:18:54.301346 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:18:54.301438 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:18:54.328531 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:18:54.328590 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:18:59.952099 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:00.107823 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:00.107856 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:00.107870 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:00.107933 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:00.107952 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:00.107961 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:00.114988 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:00.115037 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:00.142544 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:00.142612 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:01.424889 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:01.571882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:01.571915 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:01.571929 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:01.572008 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:01.572059 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:01.572069 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:01.578945 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:01.579025 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:01.606143 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:01.606185 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:05.481197 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:05.641200 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:05.641232 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:05.641251 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:05.641327 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:05.641413 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:05.641472 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:05.648664 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:05.648721 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:05.676581 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:05.676632 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:07.125100 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:07.283185 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:07.283214 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:07.283228 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:07.283333 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:07.283360 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:07.283371 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:07.290548 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:07.290640 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:07.317854 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:07.317908 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:07.788946 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:07.935847 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:07.935880 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:07.935895 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:07.935969 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:07.935988 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:07.935997 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:07.942733 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:07.942787 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:07.972135 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:07.972187 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:08.379389 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:08.543493 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:08.543526 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b004e248] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:08.543543 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:08.543620 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:08.543656 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:08.543664 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:08.550431 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:08.550477 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:19:08.578828 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:19:08.578879 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:11.381911 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:11.538272 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:11.538305 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:11.538320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:11.538386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:11.538409 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:11.538417 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:11.545214 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:11.545304 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:11.572791 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:11.572833 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:14.493741 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:14.645693 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:14.645725 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:14.645741 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:14.645805 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:14.645824 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:14.645833 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:14.653401 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:14.653509 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:19:14.683144 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:19:14.683203 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:14.980525 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:15.139154 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:15.139187 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:15.139202 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:15.139304 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:15.139339 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:15.139348 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:15.146205 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:15.146396 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:15.174690 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:15.174735 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:17.253649 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:17.398440 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:17.398472 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:17.398487 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:17.398560 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:17.398581 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:17.398591 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:17.405375 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:17.405467 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:17.432428 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:17.432476 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:18.864681 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:19.028936 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:19.028972 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:19.028992 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:19.029064 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:19.029085 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:19.029093 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:19.035874 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:19.035934 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:19:19.063812 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:19:19.063878 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:21.407080 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:21.562785 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:21.562811 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:21.562827 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:21.562913 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:21.562943 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:21.562952 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:21.569651 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:21.569696 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:21.597898 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:21.597950 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:24.941075 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:25.091029 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:25.091064 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:25.091082 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:25.091157 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:25.091179 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:25.091187 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:25.098786 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:25.098888 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:19:25.126626 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:19:25.126684 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:27.318625 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:27.474239 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:27.474274 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:27.474294 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:27.474363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:27.474387 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:27.474401 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:27.481222 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:27.481310 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:27.508393 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:27.508453 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:31.091153 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:31.255386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:31.255419 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:31.255438 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:31.255507 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:31.255524 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:31.255536 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:31.262276 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:31.262328 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:19:31.290164 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:19:31.290221 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:33.328577 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:33.487882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:33.487916 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:33.487931 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:33.488033 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:33.488066 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:33.488076 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:33.494825 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:33.494882 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:33.522719 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:33.522766 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:34.224446 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:34.369164 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:34.369200 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:34.369221 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:34.369314 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:34.369359 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:34.369368 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:34.376304 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:34.376402 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:34.403430 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:34.403488 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:34.560305 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:34.724349 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:34.724385 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:34.724404 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:34.724480 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:34.724526 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:34.724535 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:34.731335 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:34.731381 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:19:34.759177 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:19:34.759246 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:35.272331 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:35.420890 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:35.420921 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:35.420936 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:35.421008 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:35.421041 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:35.421062 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:35.428791 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:35.428902 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:19:35.456694 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:19:35.456756 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:36.273536 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:36.417407 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:36.417438 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:36.417452 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:36.417524 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:36.417555 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:36.417564 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:36.424278 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:36.424324 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:36.451672 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:36.451721 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:19:37.506297342 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:19:37.506324065 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:19:37.506330845 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:19:37.506336003 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:19:37.506339741 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:19:37.506344627 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:19:37.506349435 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:19:37.506354268 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 3, 3
2024-12-23 07:19:37.506558989 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:19:37.517927463 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:19:37.570252 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:37.570361 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:19:37.570430 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:37.570465 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3ee1e37b00"
I1223 07:19:37.570523 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:37.570559 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3ede8c3370"
I1223 07:19:37.598652 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:19:37.626592 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3ee1e37b00"
I1223 07:19:37.654306 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3ede8c3370"
I1223 07:19:37.654355 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:37.655730 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:37.655754 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:37.655776 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f400c000090"
I1223 07:19:40.875363 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:41.041050 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:41.041079 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:41.041093 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:41.041167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:41.041198 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:41.041208 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:41.047964 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:41.048012 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:19:41.075820 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:19:41.075891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:44.150141 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:44.305911 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:44.305943 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:44.305958 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:44.306036 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:44.306056 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:44.306065 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:44.312872 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:44.312955 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:44.339996 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:44.340060 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:48.526656 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
2024-12-23 07:19:48.635972664 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:19:48.635999609 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:19:48.636007390 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:19:48.636014161 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:19:48.636019057 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:19:48.636024134 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:19:48.636028366 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:19:48.636034272 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 10, 10
2024-12-23 07:19:48.636249766 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:19:48.650080323 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:19:48.675107 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:48.675141 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:48.675157 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:48.675239 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:48.675258 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:48.675267 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:48.682917 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.683019 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:19:48.710805 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:19:48.710865 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:19:48.737376003 [I:onnxruntime:log, bfc_arena.cc:347 AllocateRawInternal] Extending BFCArena for Cpu. bin_num:12 (requested) num_bytes: 2016000 (actual) rounded_bytes:2016000
2024-12-23 07:19:48.737510309 [I:onnxruntime:log, bfc_arena.cc:206 Extend] Extended allocation by 2097152 bytes.
2024-12-23 07:19:48.737522583 [I:onnxruntime:log, bfc_arena.cc:209 Extend] Total allocated bytes: 3145728
2024-12-23 07:19:48.737528089 [I:onnxruntime:log, bfc_arena.cc:212 Extend] Allocated memory at 0x7f1492dec7c0 to 0x7f1492fec7c0
I1223 07:19:48.738300 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738344 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:19:48.738416 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738432 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14cbabd380"
I1223 07:19:48.738512 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738527 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1492da8a50"
I1223 07:19:48.738604 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738620 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bca8c970"
I1223 07:19:48.738678 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738693 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bd693910"
I1223 07:19:48.738779 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738792 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14cba43d70"
I1223 07:19:48.738886 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738896 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc7eb840"
I1223 07:19:48.738947 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.738957 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14910b0bf0"
I1223 07:19:48.739074 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.739090 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14cb7dd580"
I1223 07:19:48.739147 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:48.739162 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14913b1e80"
I1223 07:19:48.770065 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:19:48.799204 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14cbabd380"
I1223 07:19:48.827779 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1492da8a50"
I1223 07:19:48.856168 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bca8c970"
I1223 07:19:48.885009 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bd693910"
I1223 07:19:48.913132 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14cba43d70"
I1223 07:19:48.941054 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc7eb840"
I1223 07:19:48.971942 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14910b0bf0"
I1223 07:19:48.999876 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14cb7dd580"
I1223 07:19:49.027640 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14913b1e80"
I1223 07:19:49.027702 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027724 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027742 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027759 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027774 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027790 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027804 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027816 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027831 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027851 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:49.027895 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f1604000090"
I1223 07:19:55.621697 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:55.786911 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:55.786946 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:55.786965 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:55.787051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:55.787070 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:55.787079 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:55.793907 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:55.793958 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:19:55.821805 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:19:55.821858 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:56.897508 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:57.047185 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:57.047219 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:57.047238 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:57.047330 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:57.047374 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:57.047383 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:57.055386 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:57.055500 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:19:57.083421 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:19:57.083474 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:58.683428 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:58.840352 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:58.840383 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:58.840399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:58.840493 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:58.840528 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:19:58.840538 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:19:58.847309 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:58.847357 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:19:58.847866 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:58.875024 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:19:58.875073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:59.009409 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:59.009438 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:59.009452 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:59.009528 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:59.009565 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:59.009574 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:59.016798 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:59.016875 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:19:59.044600 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:19:59.044649 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:19:59.388654 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:19:59.545534 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:19:59.545561 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4054738] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4054738] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:19:59.545576 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:19:59.545653 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:19:59.545686 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:19:59.545695 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:19:59.554450 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:19:59.554619 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:19:59.584783 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:19:59.584839 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:01.293085 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:01.439218 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:01.439249 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:01.439263 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:01.439336 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:01.439379 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:01.439388 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:01.446107 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:01.446155 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:20:01.466697 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:01.473706 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:20:01.473751 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:01.478710 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:01.623386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:01.623416 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:01.623430 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:01.623527 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:01.623548 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:01.623557 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:01.630340 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:01.630406 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:20:01.631411 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:01.631445 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:01.631460 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:01.631559 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:01.631591 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:01.631599 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:01.638403 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:01.638450 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:20:01.657410 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:20:01.657459 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:01.666201 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:20:01.666274 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:01.872994 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:02.017588 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:02.017628 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:02.017647 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:02.017729 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:02.017771 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:02.017784 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:02.025682 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:02.025781 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:20:02.053589 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:20:02.053660 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:20:10.471967476 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:20:10.471992621 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:20:10.472000781 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:20:10.472006768 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:20:10.472011454 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:20:10.472017001 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:20:10.472021347 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:20:10.472025979 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 2, 2
2024-12-23 07:20:10.472184244 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:20:10.483590005 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:20:10.523698 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:10.523752 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:20:10.523815 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:10.523827 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56b4b5c490"
I1223 07:20:10.551742 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:20:10.580143 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56b4b5c490"
I1223 07:20:10.580189 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:10.580210 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:10.580235 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f57fc9600a0"
I1223 07:20:12.508665 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:12.664344 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:12.664374 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:12.664389 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:12.664454 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:12.664473 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:12.664482 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:12.671200 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:12.671248 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:20:12.698607 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:20:12.698662 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:13.445309 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:13.637172 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:13.637203 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4054738] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4054738] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:13.637221 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:13.637362 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:13.637435 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:13.637446 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:13.642866 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:13.642958 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:13.675782 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:13.676323 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:15.856867 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:16.005905 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:16.005941 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:16.005961 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:16.006043 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:16.006064 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:16.006073 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:16.013098 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:16.013149 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:20:16.040997 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:20:16.041061 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:17.340559 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:17.504263 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:17.504295 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170015560] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17005ae08] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:17.504310 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:17.504383 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:17.504404 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:17.504415 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:17.512040 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:17.512137 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:20:17.540264 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:20:17.540313 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:22.172254 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:22.335787 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:22.335813 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:22.335833 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:22.335898 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:22.335919 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:22.335927 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:22.342590 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:22.342721 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:22.376335 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:22.376406 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:22.626658 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:22.783136 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:22.783166 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:22.783180 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:22.783275 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:22.783305 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:22.783314 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:22.790115 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:22.790188 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:20:22.817188 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:20:22.817244 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:28.845966 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:28.994927 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:28.994962 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:28.994977 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:28.995048 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:28.995073 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:28.995083 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:29.002002 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:29.002049 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:20:29.029721 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:20:29.029779 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:30.244008 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:30.408183 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:30.408218 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:30.408237 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:30.408312 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:30.408333 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:30.408345 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:30.415973 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:30.416073 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:20:30.443900 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:20:30.443958 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:31.057733 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:31.206246 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:31.206278 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:31.206293 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:31.206370 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:31.206407 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:31.206416 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:31.214147 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:31.214262 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:20:31.242066 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:20:31.242121 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:31.706774 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:31.863045 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:31.863079 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:31.863093 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:31.863223 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:31.863258 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:31.863266 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:31.870072 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:31.870127 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:20:31.898672 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:20:31.898735 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:33.883597 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:34.040352 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:34.040385 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54049060] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048bf8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:34.040399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:34.040490 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:34.040521 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:34.040531 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:34.047316 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:34.047411 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:20:34.074626 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:20:34.074679 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:34.084586 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:34.249935 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:34.249964 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:34.249982 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:34.250063 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:34.250106 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:34.250115 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:34.257106 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:34.257236 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:34.289453 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:34.289545 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:35.897628 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:36.054780 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:36.054818 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a540171f0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54016858] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:36.054838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:36.054933 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:36.054956 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:36.054966 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:36.062137 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:36.062190 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:20:36.090224 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:20:36.090275 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:37.442310 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:37.585736 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:37.585768 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:37.585783 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:37.585853 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:37.585875 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:37.585883 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:37.592654 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:37.592738 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:20:37.619711 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:20:37.619768 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:38.119464 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:38.276594 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:38.276624 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:38.276643 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:38.276708 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:38.276730 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:38.276738 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:38.282651 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:38.282767 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:38.311049 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:38.311106 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:20:40.321847271 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:20:40.321871923 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:20:40.321878234 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:20:40.321883495 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:20:40.321887183 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:20:40.321891110 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:20:40.321895503 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:20:40.321900262 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 5, 5
2024-12-23 07:20:40.322094321 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:20:40.333810493 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:20:40.378611 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:40.378665 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555cf9de00"
I1223 07:20:40.378731 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:40.378743 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555c352370"
I1223 07:20:40.378798 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:40.378812 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555d505270"
I1223 07:20:40.378869 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:40.378882 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555d1a9af0"
I1223 07:20:40.378937 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:40.378952 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5474c85980"
I1223 07:20:40.406790 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555cf9de00"
I1223 07:20:40.434224 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555c352370"
I1223 07:20:40.461886 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555d505270"
I1223 07:20:40.489181 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555d1a9af0"
I1223 07:20:40.516614 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5474c85980"
I1223 07:20:40.516649 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:40.516676 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:40.516687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:40.516697 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:40.516707 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:40.516729 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f55e0e100a0"
I1223 07:20:42.290115 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:42.440759 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:42.440785 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:42.440799 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:42.440878 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:42.440896 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:42.440905 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:42.446608 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:42.446708 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:42.474727 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:42.474779 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:48.670659 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:48.818484 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:48.818513 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:48.818528 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:48.818606 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:48.818628 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:48.818636 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:48.828020 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:48.828151 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:48.855992 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:48.856049 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:51.975918 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:52.133162 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:52.133193 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:52.133207 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:52.133291 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:52.133324 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:52.133332 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:52.140205 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:52.140252 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:20:52.167764 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:20:52.167828 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:53.719547 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:53.868884 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:53.868916 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:53.868936 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:53.869020 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:53.869041 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:53.869049 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:53.876111 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:53.876159 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:20:53.903882 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:20:53.903945 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:53.916331 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:54.080995 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:54.081028 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:54.081044 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:54.081113 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:54.081134 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:54.081143 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:54.087861 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:54.087905 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:20:54.115653 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:20:54.115703 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:54.563093 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:54.727646 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:54.727680 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:54.727695 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:54.727782 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:54.727819 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:20:54.727828 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:20:54.735594 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:54.735694 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:20:54.763499 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:20:54.763559 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:55.841963 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:55.990087 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:55.990120 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:55.990135 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:55.990238 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:55.990261 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:55.990269 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:55.999323 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:55.999438 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:56.027314 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:56.027385 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:20:59.665436 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:20:59.878267 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:20:59.878299 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:20:59.878319 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:20:59.878424 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:20:59.878472 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:20:59.878543 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:20:59.884252 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:20:59.884378 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:20:59.916717 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:20:59.916773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:00.647383 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:00.803677 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:00.803708 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:00.803722 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:00.803794 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:00.803814 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:00.803823 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:00.810620 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:00.810696 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:00.837841 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:00.837914 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:01.515052 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:01.664447 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:01.664478 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:01.664493 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:01.664569 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:01.664598 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:01.664607 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:01.671330 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:01.671383 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:21:01.699180 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:21:01.699243 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:02.253297 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:02.403429 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:02.403461 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:02.403477 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:02.403544 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:02.403565 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:02.403574 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:02.411315 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:02.411417 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:21:02.439210 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:21:02.439277 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:21:04.092455710 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:21:04.092485836 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:21:04.092493613 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:21:04.092500402 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:21:04.092505112 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:21:04.092509786 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:21:04.092513872 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:21:04.092518930 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 4, 4
2024-12-23 07:21:04.092768457 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:21:04.104239853 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:21:04.165437 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:04.165598 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:21:04.165747 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:04.165771 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de01e9730"
I1223 07:21:04.165833 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:04.165850 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d21b17440"
I1223 07:21:04.165912 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:04.165968 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2cfd090a90"
I1223 07:21:04.194152 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:21:04.222235 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de01e9730"
I1223 07:21:04.251063 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d21b17440"
I1223 07:21:04.279297 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2cfd090a90"
I1223 07:21:04.279371 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:04.279394 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:04.281020 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:04.281051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:04.281076 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f2e64000090"
I1223 07:21:06.888771 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:07.054179 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:07.054212 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:07.054227 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:07.054292 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:07.054312 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:07.054320 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:07.061080 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:07.061135 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:21:07.088866 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:21:07.088919 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:19.675808 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:19.902857 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:19.902889 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4065678] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:19.902909 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:19.903008 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:19.903106 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:19.903146 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:19.908221 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:19.908345 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:21:19.932871 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:19.945073 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:21:19.945158 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:20.090065 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:20.090097 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:20.090113 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:20.090192 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:20.090228 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:20.090237 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:20.097907 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:20.098005 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:21:20.125803 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:21:20.125871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:20.561444 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:20.726230 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:20.726266 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170016ff0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a768] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:20.726281 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:20.726389 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:20.726423 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:20.726432 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:20.728201 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:20.734172 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:20.734269 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:21:20.762224 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:21:20.762287 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:20.878978 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:20.879024 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff170002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff170002458] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:20.879039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:20.879112 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:20.879135 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:20.879143 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:20.886001 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:20.886042 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:21:20.913896 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:21:20.913941 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:21.552516 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:21.707139 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:21.707170 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:21.707186 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:21.707262 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:21.707293 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:21.707302 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:21.714340 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:21.714390 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:21:21.741976 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:21:21.742035 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:21.950032 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:22.094096 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:22.094130 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a5401f948] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:22.094144 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:22.094260 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:22.094264 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:22.094300 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:22.094309 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:22.101136 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:22.101239 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:22.134620 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:22.134680 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:22.261689 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:22.261721 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048750] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047f48] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:22.261735 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:22.261829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:22.261863 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:22.261872 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:22.268724 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:22.268781 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:21:22.296335 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:21:22.296387 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:23.342934 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:23.498565 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:23.498597 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:23.498612 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:23.498682 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:23.498715 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:23.498724 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:23.506452 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:23.506576 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:21:23.534426 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:21:23.534472 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:24.591628 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:24.737518 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:24.737551 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:24.737566 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:24.737639 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:24.737673 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:24.737681 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:24.745337 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:24.745441 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:21:24.773291 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:21:24.773346 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:27.774662 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:27.929879 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:27.929916 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048750] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047de8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047de8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:27.929936 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:27.930010 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:27.930027 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:27.930041 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:27.936808 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:27.936912 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:27.965038 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:27.965308 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:38.275397 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:38.431529 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:38.431564 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:38.431579 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:38.431650 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:38.431670 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:38.431678 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:38.438553 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:38.438602 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:21:38.466152 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:21:38.466207 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:42.449669 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:42.605261 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:42.605295 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:42.605314 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:42.605386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:42.605409 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:42.605417 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:42.612318 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:42.612399 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:42.639416 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:42.639470 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:43.360237 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:43.527293 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:43.527324 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:43.527339 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:43.527412 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:43.527433 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:43.527441 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:43.534175 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:43.534222 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:21:43.564667 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:21:43.564723 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:46.567656 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:46.723326 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:46.723355 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:46.723371 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:46.723449 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:46.723496 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:46.723507 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:46.730824 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:46.730878 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:21:46.758538 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:21:46.758585 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:47.976620 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:48.133743 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:48.133774 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:48.133794 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:48.133875 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:48.133942 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:48.133999 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:48.140777 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:48.140817 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:21:48.168580 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:21:48.168623 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:49.915728 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:50.064648 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:50.064682 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:50.064702 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:50.064776 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:50.064800 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:50.064810 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:50.072386 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:50.072497 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:21:50.100298 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:21:50.100354 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:52.010983 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:52.166822 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:52.166846 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:52.166866 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:52.166937 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:52.166980 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:52.166990 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:52.174290 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:52.174369 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:21:52.202328 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:21:52.202374 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:52.959304 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:53.115521 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:53.115555 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:53.115570 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:53.115661 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:53.115695 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:53.115705 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:53.122491 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:53.122577 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:53.150337 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:53.150401 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:54.525416 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:54.623291 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:54.681077 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:54.681109 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:54.681124 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:54.681195 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:54.681219 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:21:54.681242 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:21:54.688308 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:54.688354 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:21:54.716036 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:21:54.716096 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:54.838038 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:54.838101 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:54.838123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:54.838258 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:54.838403 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:54.838471 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:54.844075 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:54.844181 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:21:54.875999 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:21:54.876065 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:55.532803 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:55.700001 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:55.700033 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:55.700052 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:55.700123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:55.700142 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:55.700149 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:55.706867 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:55.706917 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:21:55.734730 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:21:55.734788 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:21:57.331577 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:21:57.476956 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:21:57.476988 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:21:57.477003 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:21:57.477085 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:21:57.477120 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:21:57.477129 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:21:57.483887 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:21:57.483962 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:21:57.510975 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:21:57.511027 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:04.609466 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:04.765489 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:04.765523 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:04.765538 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:04.765616 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:04.765633 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:04.765642 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:04.772395 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:04.772448 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:04.803243 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:04.803299 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:05.565374 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:05.714379 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:05.714416 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:05.714436 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:05.714516 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:05.714539 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:05.714547 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:05.722336 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:05.722457 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:22:05.750668 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:22:05.750737 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:10.454347 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:10.618409 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:10.618443 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:10.618457 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:10.618529 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:10.618550 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:10.618560 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:10.625361 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:10.625406 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:22:10.653237 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:22:10.653288 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:11.603844 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:11.634800 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:11.755826 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:11.755855 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:11.755871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:11.755940 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:11.755979 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:11.755988 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:11.775292 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:11.775417 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:22:11.789934 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:11.789969 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:11.789984 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:11.790063 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:11.790093 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:11.790103 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:11.797006 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:11.797091 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:22:11.803730 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:22:11.803791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:11.824180 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:22:11.824235 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:13.997720 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:14.146012 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:14.146045 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:14.146060 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:14.146140 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:14.146161 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:14.146168 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:14.153775 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:14.153863 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:22:14.181610 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:22:14.181662 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:15.665954 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:15.821575 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:15.821609 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:15.821627 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:15.821701 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:15.821722 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:15.821731 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:15.828864 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:15.828921 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:22:15.856653 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:22:15.856703 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:17.620339 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:17.790459 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:17.790491 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:17.790507 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:17.790592 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:17.790610 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:17.790618 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:17.797305 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:17.797351 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:22:17.825078 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:22:17.825133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:22:23.552294 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:23.709128 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:23.709158 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048020] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54048558] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:23.709173 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:23.709242 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:23.709282 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:23.709296 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:23.716107 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:23.716146 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:23.743617 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:23.743657 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
2024-12-23 07:22:24.170717167 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:235 SerializeProfileV2] [TensorRT EP] In SerializeProfileV2()
2024-12-23 07:22:24.170741879 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:240 SerializeProfileV2] [TensorRT EP] input tensor is 'images'
2024-12-23 07:22:24.170748674 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 3
2024-12-23 07:22:24.170753685 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 3, 640, 640, 640
2024-12-23 07:22:24.170758826 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 2
2024-12-23 07:22:24.170764532 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 2, 640, 640, 640
2024-12-23 07:22:24.170768879 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:245 operator()] [TensorRT EP] profile #0, dim is 0
2024-12-23 07:22:24.170773905 [V:onnxruntime:log, tensorrt_execution_provider_utils.h:250 operator()] [TensorRT EP] 0, 1, 3, 3
2024-12-23 07:22:24.170986281 [V:onnxruntime:log, tensorrt_execution_provider.cc:3678 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.profile
2024-12-23 07:22:24.182570001 [V:onnxruntime:log, tensorrt_execution_provider.cc:3695 operator()] [TensorRT EP] Serialized /models/screen/1/TensorrtExecutionProvider_TRTKernel_graph_main_graph_3987735517180450092_0_0_fp16_sm75.engine
I1223 07:22:24.238125 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:24.238197 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:22:24.238265 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:24.238279 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f142c097be0"
I1223 07:22:24.238349 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:24.238363 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1436cb7220"
I1223 07:22:24.266289 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:22:24.294043 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f142c097be0"
I1223 07:22:24.321856 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1436cb7220"
I1223 07:22:24.321923 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:24.321946 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:24.324170 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:24.324216 1 pinned_memory_manager.cc:226] "pinned memory deallocation: addr 0x7f1606ee00a0"
I1223 07:22:26.023793 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:26.172279 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:26.172314 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:26.172329 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:26.172429 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:26.172465 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:26.172478 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:26.180242 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:26.180341 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:22:26.208320 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:22:26.208369 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:26.683248 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:26.838643 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:26.838675 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54016eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:26.838694 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:26.838786 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:26.838821 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:26.838831 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:26.845761 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:26.845887 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:22:26.874930 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:22:26.874975 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:29.728350 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:29.883798 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:29.883829 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54016eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540461b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:29.883843 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:29.883932 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:29.883966 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:29.883975 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:29.890777 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:29.890828 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:29.918314 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:29.918371 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:32.200055 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:32.356516 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:32.356550 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:32.356571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:32.356662 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:32.356684 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:32.356695 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:32.365788 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:32.365903 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:22:32.393786 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:22:32.393859 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:32.508109 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:32.652577 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:32.652609 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:32.652629 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:32.652707 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:32.652727 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:32.652737 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:32.659549 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:32.659634 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:22:32.686680 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:22:32.686731 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:22:34.269496 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:34.434290 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:34.434322 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:34.434337 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:34.434435 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:34.434493 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:34.434513 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:34.441249 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:34.441298 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:22:34.468935 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:22:34.468991 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:37.291197 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:37.448317 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:37.448347 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:37.448362 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:37.448430 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:37.448461 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:37.448471 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:37.455211 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:37.455252 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:37.482757 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:37.482804 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:44.039910 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:44.196387 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:44.196428 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:44.196445 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:44.196546 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:44.196580 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:44.196590 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:44.204341 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:44.204395 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:22:44.232116 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:22:44.232186 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:45.023012 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:45.181288 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:45.181319 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:45.181333 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:45.181405 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:45.181458 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:45.181469 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:45.188712 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:45.188797 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:22:45.215824 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:22:45.215882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:22:46.635777 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:46.792490 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:46.792520 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:46.792539 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:46.792608 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:46.792723 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:46.792734 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:46.799522 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:46.799565 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:46.826975 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:46.827032 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:49.021881 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:49.178806 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:49.178836 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:49.178851 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:49.178943 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:49.178989 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:49.178999 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:49.185759 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:49.185848 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:22:49.212906 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:22:49.212955 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:49.991568 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:50.147711 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:50.147751 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:50.147773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:50.147849 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:50.147876 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:50.147890 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:50.156913 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:50.157018 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:22:50.184975 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:22:50.185039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:51.846009 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:51.990567 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:51.990600 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:51.990614 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:51.990687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:51.990719 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:22:51.990732 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:22:51.997503 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:51.997555 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:22:52.018161 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:22:52.024969 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:22:52.025037 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:22:52.181929 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:22:52.181963 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:22:52.181979 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:22:52.182047 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:22:52.182066 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:22:52.182073 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:22:52.188826 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:22:52.188871 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:22:52.216683 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:22:52.216731 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:01.413400 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:01.569340 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:01.569363 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:01.569377 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:01.569462 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:01.569493 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:01.569504 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:01.576273 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:01.576354 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:23:01.603341 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:23:01.603393 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:03.000428 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:03.149635 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:03.149668 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:03.149687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:03.149766 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:03.149816 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:03.149825 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:03.157659 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:03.157760 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:23:03.185609 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:23:03.185687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:04.895701 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:05.045022 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:05.045055 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:05.045070 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:05.045167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:05.045210 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:05.045219 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:05.052922 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:05.053030 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:23:05.080717 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:23:05.080784 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:05.237365 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:05.392372 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:05.392403 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:05.392422 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:05.392491 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:05.392536 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:05.392546 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:05.399869 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:05.399973 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:23:05.427823 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:23:05.427868 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:23:08.339951 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:08.495836 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:08.495866 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:08.495881 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:08.495957 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:08.495974 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:08.495982 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:08.502799 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:08.502753 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:08.502793 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:23:08.530204 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:23:08.530246 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:08.658340 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:08.658371 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:08.658386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:08.658459 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:08.658478 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:08.658486 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:08.666164 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:08.666216 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:23:08.693883 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:23:08.693946 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:23:12.892673 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:13.048141 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:13.048172 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:13.048187 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:13.048269 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:13.048303 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:13.048313 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:13.057061 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:13.057164 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:23:13.084922 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:23:13.084981 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:14.025093 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:14.180580 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:14.180609 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:14.180623 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:14.180699 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:14.180742 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:14.180752 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:14.188106 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:14.188157 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:23:14.216050 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:23:14.216090 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:17.117855 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:17.273521 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:17.273553 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:17.273569 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:17.273642 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:17.273677 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:17.273684 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:17.281363 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:17.281421 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:23:17.309061 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:23:17.309130 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:18.918722 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:19.073070 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:19.073102 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:19.073117 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:19.073214 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:19.073259 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:19.073268 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:19.080668 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:19.080773 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:23:19.108986 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:23:19.109041 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:22.088252 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:22.252275 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:22.252307 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:22.252321 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:22.252402 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:22.252443 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:22.252452 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:22.259118 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:22.259166 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:23:22.286839 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:23:22.286900 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:25.698784 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:25.854302 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:25.854335 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:25.854352 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:25.854425 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:25.854447 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:25.854458 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:25.863337 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:25.863445 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:23:25.891381 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:23:25.891444 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:27.584184 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:27.740157 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:27.740189 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:27.740209 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:27.740288 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:27.740310 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:27.740320 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:27.747011 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:27.747079 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:23:27.774048 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:23:27.774095 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:29.703978 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:29.789354 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:29.868304 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:29.868339 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:29.868358 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:29.868434 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:29.868455 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:29.868462 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:29.875149 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:29.875202 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:23:29.903095 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:23:29.903153 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:29.944823 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:29.944853 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:29.944868 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:29.944933 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:29.944951 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:29.944960 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:29.952755 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:29.952816 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:23:29.980518 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:23:29.980591 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:32.641148 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:32.797182 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:32.797210 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:32.797225 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:32.797303 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:32.797336 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:32.797345 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:32.804525 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:32.804569 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:23:32.831943 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:23:32.831997 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:34.743934 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:34.893300 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:34.893335 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:34.893353 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:34.893456 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:34.893492 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:34.893502 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:34.901197 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:34.901290 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:23:34.929361 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:23:34.929410 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:38.309939 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:38.465153 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:38.465183 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:38.465198 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:38.465292 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:38.465326 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:38.465334 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:38.472569 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:38.472626 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:23:38.500550 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:23:38.500602 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:42.494742 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:42.649730 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:42.649758 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:42.649774 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:42.649888 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:42.649919 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:42.649928 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:42.657336 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:42.657425 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:23:42.685369 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:23:42.685415 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:46.512458 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:46.667595 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:46.667625 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:46.667640 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:46.667746 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:46.667781 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:46.667791 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:46.675076 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:46.675126 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:23:46.702995 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:23:46.703041 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:47.799985 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:47.955726 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:47.955753 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:47.955768 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:47.955857 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:47.955888 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:47.955898 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:47.963153 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:47.963246 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:23:47.991091 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:23:47.991137 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:49.643030 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:49.798401 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:49.798438 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:49.798458 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:49.798549 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:49.798571 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:49.798579 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:49.807554 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:49.807666 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:23:49.835503 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:23:49.835582 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:51.110069 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:51.265760 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:51.265791 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:51.265806 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:51.265874 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:51.265891 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:51.265899 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:51.272668 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:51.272737 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:23:51.300251 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:23:51.300303 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:51.779927 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:51.929022 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:51.929057 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:51.929077 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:51.929157 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:51.929201 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:51.929212 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:51.936817 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:51.936919 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:23:51.964681 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:23:51.964755 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:52.720523 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:52.876011 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:52.876044 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:52.876064 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:52.876138 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:52.876165 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:52.876175 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:52.884076 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:52.884130 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:23:52.912634 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:23:52.912676 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:54.524862 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:54.669776 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:54.669805 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:54.669819 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:54.669900 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:54.669915 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:54.669923 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:54.677181 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:54.677268 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:23:54.705083 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:23:54.705124 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:58.744410 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:58.760118 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:23:58.895773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:58.895805 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:58.895820 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:58.895899 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:58.895941 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:23:58.895951 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:23:58.902625 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:58.902668 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:23:58.929658 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:23:58.924649 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:23:58.924684 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:23:58.924699 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:23:58.924779 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:23:58.924849 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:23:58.924858 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:23:58.931715 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:23:58.931765 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:23:58.959583 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:23:58.959642 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:23:58.929703 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:03.564197 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:03.719683 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:03.719714 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:03.719729 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:03.719802 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:03.719924 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:03.719998 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:03.727629 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:03.727684 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:03.755508 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:03.755554 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:04.259740 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:04.403872 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:04.403903 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:04.403922 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:04.403998 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:04.404018 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:04.404026 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:04.411383 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:04.411475 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:04.439346 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:04.439390 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:08.089457 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:08.244695 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:08.244724 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:08.244739 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:08.244804 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:08.244823 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:08.244832 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:08.251936 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:08.251995 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:08.279820 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:08.279866 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:09.701003 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:09.848600 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:09.848632 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:09.848648 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:09.848765 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:09.848788 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:09.848796 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:09.856425 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:09.856533 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:24:09.885295 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:24:09.885350 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:12.798962 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:12.882159 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:12.950007 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:12.950040 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:12.950059 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:12.950122 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:12.950143 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:12.950155 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:12.956858 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:12.956935 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:24:12.983072 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:24:12.983133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:13.037571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:13.037601 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:13.037616 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:13.037693 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:13.037728 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:13.037738 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:13.045111 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:13.045227 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:13.073659 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:13.073704 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:13.272964 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:13.417627 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:13.417658 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:13.417673 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:13.417754 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:13.417846 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:13.417855 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:13.425150 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:13.425199 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:13.452925 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:13.452972 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:14.856024 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:15.021920 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:15.021956 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:15.021971 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:15.022034 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:15.022055 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:15.022062 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:15.028792 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:15.028844 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:24:15.056512 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:24:15.056567 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:19.888337 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:20.038512 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:20.038546 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:20.038561 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:20.038639 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:20.038664 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:20.038672 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:20.046416 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:20.046513 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:24:20.074214 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:24:20.074269 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:21.346548 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:21.496702 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:21.496732 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:21.496747 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:21.496842 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:21.496874 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:21.496887 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:21.503641 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:21.503690 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:24:21.530250 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:24:21.530299 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:26.631681 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:26.795999 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:26.796033 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:26.796053 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:26.796133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:26.796152 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:26.796161 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:26.802961 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:26.803011 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:24:26.830830 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:24:26.830885 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:28.579422 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:28.734950 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:28.734980 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d5d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:28.734997 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:28.735104 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:28.735147 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:28.735157 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:28.735973 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:28.742606 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:28.742696 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:28.770646 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:28.770691 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:28.893995 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:28.894028 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:28.894047 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:28.894174 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:28.894230 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:28.894252 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:28.901533 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:28.901589 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:28.929366 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:28.929411 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:30.296491 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:30.447653 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:30.447686 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54048670] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a54047268] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:30.447701 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:30.447767 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:30.447785 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:30.447794 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:30.454614 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:30.454716 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:24:30.484577 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:24:30.484658 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:33.602578 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:33.757315 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:33.757344 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:33.757363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:33.757437 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:33.757477 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:33.757488 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:33.764808 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:33.764892 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:33.792876 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:33.792921 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:37.389334 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:37.539933 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:37.539965 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:37.539979 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:37.540054 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:37.540096 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:37.540106 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:37.546882 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:37.546924 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:24:37.573722 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:24:37.573782 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:38.396398 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:38.560279 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:38.560305 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:38.560320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:38.560384 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:38.560425 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:38.560434 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:38.567216 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:38.567265 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:24:38.595091 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:24:38.595145 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:39.924880 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:40.080593 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:40.080625 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:40.080644 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:40.080719 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:40.080762 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:40.080771 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:40.088101 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:40.088146 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:40.115939 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:40.115984 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:42.571109 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:42.726679 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:42.726709 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:42.726724 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:42.726786 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:42.726827 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:42.726842 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:42.734642 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:42.734727 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:42.762657 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:42.762701 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:44.818274 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:44.973534 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:44.973563 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:44.973579 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:44.973646 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:44.973665 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:44.973673 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:44.980901 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:44.980963 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:45.008689 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:45.008738 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:45.751289 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:45.899346 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:45.899378 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:45.899397 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:45.899462 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:45.899505 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:45.899515 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:45.907189 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:45.907302 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:24:45.935047 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:24:45.935100 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:49.214870 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:49.372909 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:49.372939 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c046840] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c04d4d8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:49.372954 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:49.373027 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:49.373060 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:49.373070 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:49.380516 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:49.380616 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:49.408563 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:49.408616 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:49.846944 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:50.023616 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:50.023648 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:50.023663 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:50.023745 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:50.023789 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:50.023797 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:50.030542 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:50.030590 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:24:50.058418 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:24:50.058473 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:52.206783 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:52.355628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:52.355661 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:52.355680 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:52.355756 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:52.355799 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:24:52.355812 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:24:52.363029 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:52.363080 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:24:52.390939 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:24:52.390987 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:53.660963 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:53.810076 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:53.810110 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:53.810130 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:53.810199 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:53.810246 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:53.810255 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:53.818084 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:53.818195 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:24:53.845971 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:24:53.846031 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:24:58.580629 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:24:58.736386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:24:58.736415 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:24:58.736433 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:24:58.736499 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:24:58.736519 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:24:58.736527 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:24:58.743828 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:24:58.743921 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:24:58.771857 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:24:58.771905 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:00.390443 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:00.554229 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:00.554265 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:00.554284 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:00.554355 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:00.554372 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:00.554382 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:00.561113 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:00.561172 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:25:00.588939 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:25:00.589008 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:05.960379 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:06.117864 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:06.117894 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:06.117909 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:06.117984 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:06.118042 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:06.118051 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:06.125310 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:06.125359 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:25:06.153289 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:25:06.153331 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:06.820473 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:06.976460 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:06.976495 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:06.976511 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:06.976607 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:06.976640 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:06.976649 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:06.984410 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:06.984466 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:25:07.012168 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:25:07.012240 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:08.724278 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:08.848087 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:08.871993 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:08.872026 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:08.872041 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:08.872118 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:08.872159 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:08.872171 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:08.879862 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:08.879966 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:25:08.908649 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:25:08.908697 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:09.000201 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:09.000233 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:09.000248 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:09.000316 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:09.000335 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:09.000343 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:09.007100 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:09.007191 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:25:09.033490 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:25:09.033538 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:09.734871 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:09.891007 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:09.891039 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:09.891059 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:09.891124 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:09.891144 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:09.891153 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:09.898454 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:09.898541 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:25:09.926444 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:25:09.926487 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:11.310641 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:11.466412 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:11.466446 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:11.466461 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:11.466543 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:11.466587 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:11.466596 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:11.475510 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:11.475616 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:25:11.504020 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:25:11.504095 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:15.904739 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:16.061005 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:16.061040 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:16.061057 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:16.061169 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:16.061196 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:16.061204 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:16.068921 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:16.068980 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:25:16.097689 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:25:16.097757 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:16.511722 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:16.662886 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:16.662918 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:16.662937 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:16.663032 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:16.663052 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:16.663060 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:16.669748 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:16.669795 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:25:16.696321 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:25:16.696367 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:18.729207 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:18.894226 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:18.894252 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:18.894268 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:18.894345 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:18.894366 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:18.894375 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:18.901188 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:18.901235 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:25:18.929104 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:25:18.929169 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:19.700850 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:19.823698 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:19.855957 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:19.855988 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:19.856003 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:19.856101 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:19.856123 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:19.856131 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:19.863373 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:19.863422 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:25:19.891103 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:25:19.891145 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:19.978978 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:19.979010 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:19.979027 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:19.979099 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:19.979121 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:19.979130 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:19.988222 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:19.988345 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:25:20.016150 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:25:20.016220 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:27.082415 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:27.238158 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:27.238191 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:27.238209 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:27.238287 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:27.238333 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:27.238342 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:27.246057 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:27.246155 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:25:27.274426 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:25:27.274467 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:30.126818 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:30.272482 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:30.272513 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:30.272528 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:30.272590 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:30.272610 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:30.272618 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:30.279084 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:30.279734 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:30.279787 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:25:30.307640 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:25:30.307686 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:30.434639 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:30.434674 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:30.434689 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:30.434798 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:30.434821 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:30.434862 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:30.442584 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:30.442639 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:25:30.470527 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:25:30.470584 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:32.976202 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:33.124228 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:33.124266 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:33.124285 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:33.124365 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:33.124387 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:33.124398 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:33.132024 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:33.132148 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:25:33.159970 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:25:33.160030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:35.719505 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:35.875393 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:35.875424 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:35.875443 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:35.875522 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:35.875553 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:35.875563 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:35.883455 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:35.883566 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:25:35.912196 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:25:35.912247 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:36.275876 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:36.432168 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:36.432202 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:36.432217 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:36.432315 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:36.432352 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:36.432361 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:36.441308 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:36.441415 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:25:36.469197 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:25:36.469252 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:37.499106 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:37.644010 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:37.644043 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:37.644057 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:37.644144 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:37.644177 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:37.644186 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:37.651441 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:37.651493 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:25:37.679240 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:25:37.679298 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:42.064371 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:42.228249 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:42.228281 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:42.228296 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:42.228364 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:42.228382 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:42.228389 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:42.235112 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:42.235162 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:25:42.263095 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:25:42.263147 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:43.046094 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:43.202054 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:43.202092 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:43.202111 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:43.202198 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:43.202219 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:43.202228 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:43.209954 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:43.210016 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:25:43.237590 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:25:43.237656 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:44.390702 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:44.541682 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:44.541716 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:44.541733 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:44.541808 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:44.541854 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:44.541862 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:44.548722 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:44.548805 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:25:44.575068 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:25:44.575125 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:50.598484 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:50.749652 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:50.749690 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:50.749710 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:50.749791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:50.749834 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:50.749845 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:50.756743 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:50.756792 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:25:50.783579 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:25:50.783654 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:51.422827 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:51.578464 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:51.578491 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:51.578505 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:51.578585 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:51.578647 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:51.578656 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:51.586095 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:51.586186 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:25:51.614125 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:25:51.614170 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:53.165208 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:53.309085 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:53.309118 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:53.309138 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:53.309213 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:53.309235 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:53.309243 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:53.316445 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:53.316497 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:25:53.344316 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:25:53.344363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:53.544815 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:53.698954 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:53.698988 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:53.699024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:53.699087 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:53.699104 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:25:53.699113 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:25:53.706952 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:53.707052 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:25:53.734898 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:25:53.734960 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:56.263701 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:56.415251 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:56.415284 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:56.415298 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:56.415370 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:56.415392 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:56.415413 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:56.422177 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:56.422264 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:25:56.448588 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:25:56.448655 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:25:57.018506 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:25:57.174581 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:25:57.174617 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:25:57.174632 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:25:57.174708 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:25:57.174742 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:25:57.174751 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:25:57.183622 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:25:57.183723 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:25:57.211396 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:25:57.211454 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:02.609368 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:02.616179 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:02.740088 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:02.764628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:02.764660 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:02.764675 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:02.764737 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:02.764755 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:02.764761 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:02.771439 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:02.771483 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:26:02.783407 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:02.783442 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:02.783457 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:02.783550 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:02.783582 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:02.783593 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:02.790342 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:02.799218 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:26:02.799274 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:02.790397 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:26:02.818229 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:26:02.818298 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:02.888322 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:02.888346 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:02.888364 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:02.888433 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:02.888470 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:02.888479 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:02.896216 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:02.896338 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:26:02.924100 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:26:02.924175 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:05.650869 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:05.806551 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:05.806586 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:05.806606 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:05.806700 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:05.806746 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:05.806755 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:05.814406 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:05.814456 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:26:05.842069 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:26:05.842123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:26:08.427986 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:08.592778 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:08.592809 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:08.592830 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:08.592897 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:08.592918 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:08.592925 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:08.599676 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:08.599719 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:26:08.627497 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:26:08.627551 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:12.071328 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:12.219685 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:12.219719 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:12.219734 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:12.219817 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:12.219853 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:12.219862 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:12.227511 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:12.227606 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:26:12.255296 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:26:12.255344 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:12.596643 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:12.744977 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:12.745010 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:12.745025 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:12.745098 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:12.745119 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:12.745128 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:12.752795 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:12.752912 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:26:12.781312 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:26:12.781362 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:15.265645 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:15.421560 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:15.421594 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:15.421610 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:15.421682 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:15.421704 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:15.421723 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:15.430634 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:15.430743 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:26:15.458633 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:26:15.458696 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:18.549306 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:18.713531 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:18.713565 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:18.713580 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:18.713646 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:18.713665 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:18.713671 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:18.720447 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:18.720504 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:26:18.748394 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:26:18.748454 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:19.866927 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:20.031130 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:20.031163 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:20.031183 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:20.031255 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:20.031276 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:20.031284 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:20.038045 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:20.038088 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:26:20.065779 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:26:20.065838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:23.308028 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:23.463773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:23.463807 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:23.463826 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:23.463893 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:23.463914 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:23.463921 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:23.471379 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:23.471480 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:26:23.499317 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:26:23.499363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:24.354938 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:24.503513 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:24.503546 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:24.503562 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:24.503638 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:24.503680 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:24.503692 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:24.511347 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:24.511457 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:26:24.539214 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:26:24.539277 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:25.259463 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:25.408899 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:25.408933 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:25.408951 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:25.409042 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:25.409064 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:25.409072 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:25.416774 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:25.416870 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:26:25.444766 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:26:25.444831 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:30.777038 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:30.943820 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:30.943858 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:30.943879 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:30.943988 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:30.944029 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:30.944042 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:30.950847 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:30.950897 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:26:30.978612 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:26:30.978668 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:31.295257 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:31.459992 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:31.460024 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:31.460039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:31.460107 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:31.460128 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:31.460136 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:31.466971 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:31.467024 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:26:31.494693 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:26:31.494752 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:32.324692 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:32.481212 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:32.481247 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:32.481263 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:32.481360 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:32.481383 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:32.481391 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:32.489165 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:32.489218 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:26:32.516902 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:26:32.516969 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:38.986804 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:39.142628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:39.142659 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:39.142678 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:39.142747 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:39.142791 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:39.142799 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:39.150224 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:39.150277 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f5780304490"
I1223 07:26:39.180430 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f5780304490"
I1223 07:26:39.180492 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:39.477695 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:39.622432 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:39.622462 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f579c045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f579c014688] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:39.622478 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:39.622540 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:39.622558 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:39.622575 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:39.629970 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:39.630069 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f56d5eac550"
I1223 07:26:39.658036 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f56d5eac550"
I1223 07:26:39.658087 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:40.700750 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:40.849764 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:40.849790 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:40.849809 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:40.849881 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:40.849925 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:40.849934 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:40.857618 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:40.857725 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:26:40.885492 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:26:40.885545 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:41.750188 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:41.778815 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:41.909190 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:41.909223 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:41.909243 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:41.909337 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:41.909409 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:41.909468 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:41.918877 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:41.918995 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:26:41.937545 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:41.937578 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:41.937592 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:41.937661 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:41.937726 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:41.937738 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:41.944558 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:41.944646 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:26:41.947050 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:26:41.947109 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:41.972285 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:26:41.972355 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:43.045278 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:43.189734 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:43.189769 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:43.189785 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:43.189871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:43.189905 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:43.189915 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:43.197668 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:43.197725 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:26:43.225498 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:26:43.225572 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:50.337159 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:50.492689 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:50.492724 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:50.492740 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:50.492838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:50.492874 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:50.492882 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:50.501753 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:50.501867 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:26:50.529577 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:26:50.529636 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:52.079882 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:52.235712 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:52.235745 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:52.235760 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:52.235841 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:52.235872 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:52.235893 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:52.244247 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:52.244385 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:26:52.272648 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:26:52.272721 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:52.449484 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:52.597778 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:52.597812 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:52.597829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:52.597894 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:52.597915 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:52.597922 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:52.605633 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:52.605749 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:26:52.633491 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:26:52.633549 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:54.035288 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:54.184628 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:54.184663 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:54.184677 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:54.184773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:54.184807 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:54.184816 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:54.192694 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:54.192810 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:26:54.220825 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:26:54.220892 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:56.486892 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:56.645534 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:56.645568 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:56.645584 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:56.645655 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:56.645689 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:26:56.645698 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:26:56.652417 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:56.652475 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:26:56.680036 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:26:56.680115 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:26:59.503249 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:26:59.658703 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:26:59.658738 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:26:59.658753 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:26:59.658835 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:26:59.658869 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:26:59.658878 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:26:59.665656 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:26:59.665700 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:26:59.693391 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:26:59.693456 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:00.079299 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:00.247669 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:00.247703 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:00.247718 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:00.247798 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:00.247832 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:00.247841 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:00.254503 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:00.254556 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:27:00.283811 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:27:00.283871 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:09.339821 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:09.504080 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:09.504114 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:09.504133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:09.504212 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:09.504233 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:09.504241 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:09.510911 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:09.510955 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:27:09.541607 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:27:09.541660 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:09.676831 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:09.833288 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:09.833327 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:09.833342 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:09.833416 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:09.833437 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:09.833446 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:09.841640 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:09.841740 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:27:09.869912 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:27:09.869976 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:10.175222 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:10.330649 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:10.330685 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:10.330704 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:10.330782 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:10.330802 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:10.330809 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:10.338316 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:10.338367 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:27:10.365856 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:27:10.365905 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:13.737878 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:13.886271 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:13.886305 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:13.886321 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:13.886419 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:13.886442 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:13.886451 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:13.894154 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:13.894267 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:27:13.922033 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:27:13.922098 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:14.190916 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:14.347391 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:14.347427 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:14.347445 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:14.347517 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:14.347539 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:14.347547 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:14.355298 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:14.355419 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:27:14.383564 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:27:14.383634 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:15.271895 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:15.428308 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:15.428341 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:15.428361 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:15.428441 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:15.428463 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:15.428473 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:15.437680 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:15.437793 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:27:15.465970 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:27:15.466019 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:16.349730 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:16.494710 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:16.494744 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:16.494759 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:16.494829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:16.494848 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:16.494856 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:16.502521 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:16.502577 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:27:16.530407 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:27:16.530462 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:16.687651 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:16.843558 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:16.843589 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:16.843602 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:16.843675 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:16.843716 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:16.843726 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:16.850518 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:16.850560 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:27:16.878160 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:27:16.878212 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:17.035949 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:17.192687 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:17.192726 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:17.192741 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:17.192823 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:17.192844 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:17.192851 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:17.199542 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:17.199599 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:27:17.227400 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:27:17.227479 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:19.580659 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:19.729413 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:19.729449 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:19.729468 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:19.729562 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:19.729584 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:19.729593 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:19.737271 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:19.737377 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:27:19.765285 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:27:19.765343 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:29.056379 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:29.212086 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:29.212119 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:29.212134 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:29.212211 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:29.212231 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:29.212239 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:29.219127 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:29.219209 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:27:29.246327 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:27:29.246375 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:30.184544 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:30.339730 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:30.339768 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:30.339789 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:30.339868 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:30.339887 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:30.339897 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:30.348766 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:30.348873 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:27:30.376675 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:27:30.376725 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:36.388457 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:36.544085 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:36.544117 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:36.544133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:36.544216 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:36.544249 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:36.544258 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:36.551838 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:36.551895 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:27:36.579556 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:27:36.579602 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:37.229688 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:37.394761 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:37.394796 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:37.394814 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:37.394897 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:37.394916 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:37.394926 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:37.401643 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:37.401697 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:27:37.429366 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:27:37.429435 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:38.032275 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:38.187782 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:38.187814 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:38.187829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:38.187911 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:38.187953 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:38.187964 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:38.194723 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:38.194777 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:27:38.222477 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:27:38.222551 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:38.585088 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:38.741474 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:38.741509 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:38.741525 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:38.741604 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:38.741647 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:38.741656 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:38.748557 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:38.748603 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:27:38.776002 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:27:38.776049 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:39.794563 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:39.959582 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:39.959614 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:39.959634 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:39.959712 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:39.959733 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:39.959741 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:39.966514 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:39.966568 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:27:39.995249 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:27:39.995314 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:40.470500 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"

I1223 07:27:40.619358 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:40.619392 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:40.619407 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:40.619480 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:40.619502 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:40.619520 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:40.627221 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:40.627319 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:27:40.655122 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:27:40.655196 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:41.168006 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:41.318807 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:41.318845 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:41.318864 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:41.318939 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:41.318983 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:41.318993 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:41.327086 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:41.327191 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:27:41.355298 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:27:41.355367 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:42.731100 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:42.887285 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:42.887315 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:42.887329 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:42.887399 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:42.887420 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:42.887429 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:42.894167 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:42.894251 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:27:42.921276 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:27:42.921344 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:46.627215 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:46.775074 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:46.775108 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:46.775123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:46.775223 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:46.775245 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:46.775254 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:46.782866 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:46.782961 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:27:46.777213 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:46.810678 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:27:46.810728 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:46.933324 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:46.933364 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:46.933379 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:46.933460 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:46.933503 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:46.933512 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:46.940310 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:46.940366 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:27:46.967968 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:27:46.968042 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:53.913212 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:54.077516 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:54.077551 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:54.077571 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:54.077639 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:54.077657 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:27:54.077669 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:27:54.084359 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:54.084408 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:27:54.112198 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:27:54.112253 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:58.766664 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:27:58.915350 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:27:58.915389 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:27:58.915404 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:27:58.915478 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:27:58.915501 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:27:58.915509 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:27:58.923232 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:27:58.923343 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:27:58.951155 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:27:58.951213 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:27:59.966942 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:00.123124 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:00.123162 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:00.123178 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:00.123260 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:00.123293 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:00.123303 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:00.131505 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:00.131622 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:28:00.159754 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:28:00.159828 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:01.233002 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:01.390547 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:01.390578 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:01.390592 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:01.390657 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:01.390674 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:01.390681 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:01.397432 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:01.397477 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:28:01.424958 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:28:01.425004 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:02.025163 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:02.181381 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:02.181417 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:02.181432 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:02.181514 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:02.181548 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:02.181558 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:02.189308 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:02.189425 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:28:02.217646 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:28:02.217722 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:03.229651 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:03.394268 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:03.394300 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:03.394320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:03.394420 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:03.394454 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:03.394463 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:03.401260 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:03.401309 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:28:03.429149 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:28:03.429209 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:06.308956 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:06.468760 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:06.468792 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:06.468811 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:06.468882 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:06.468900 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:06.468913 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:06.475616 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:06.475667 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:28:06.503410 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:28:06.503480 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:06.626908 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:06.782676 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:06.782712 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:06.782726 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:06.782829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:06.782870 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:06.782880 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:06.789782 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:06.789868 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:28:06.816993 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:28:06.817073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:07.241772 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:07.398006 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:07.398042 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:07.398057 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:07.398142 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:07.398173 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:07.398181 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:07.405063 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:07.405118 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:28:07.432637 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:28:07.432711 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:12.867832 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:13.023733 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:13.023765 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:13.023780 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:13.023850 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:13.023869 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:13.023878 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:13.030723 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:13.030770 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:28:13.058216 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:28:13.058268 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:14.947213 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:15.103109 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:15.103145 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:15.103159 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:15.103246 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:15.103280 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:15.103289 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:15.111563 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:15.111667 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:28:15.139765 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:28:15.139835 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:17.635254 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:17.799341 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:17.799376 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:17.799395 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:17.799469 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:17.799513 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:17.799526 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:17.806265 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:17.806315 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff14924c920"
I1223 07:28:17.834108 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff14924c920"
I1223 07:28:17.834181 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:22.500909 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:22.649730 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:22.649763 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7ff170045eb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7ff17001a058] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:22.649783 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:22.649906 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:22.649929 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:22.649938 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:22.657562 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:22.657676 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7ff0a5ceaaa0"
I1223 07:28:22.685622 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7ff0a5ceaaa0"
I1223 07:28:22.685685 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:23.302027 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:23.461657 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:23.461692 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:23.461708 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:23.461795 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:23.461828 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:23.461837 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:23.468619 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:23.468670 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:28:23.471105 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:23.496236 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:28:23.496299 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:23.625889 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:23.625923 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:23.625938 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:23.626020 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:23.626055 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:23.626066 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:23.632885 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:23.632979 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:28:23.659946 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:28:23.659994 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:25.871612 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:26.027722 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:26.027759 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:26.027775 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:26.027876 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:26.027911 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:26.027921 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:26.036926 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:26.037039 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:28:26.064877 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:28:26.064951 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:29.147378 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:29.303220 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:29.303251 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:29.303271 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:29.303338 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:29.303385 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:29.303394 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:29.310220 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:29.310261 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:28:29.316375 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:29.337770 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:28:29.337829 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:29.343173 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:29.467421 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:29.500015 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:29.500048 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:29.467454 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:29.467469 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:29.500063 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:29.500143 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:29.500183 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:29.500194 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:29.467529 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:29.467562 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:29.467571 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:29.475358 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:29.475450 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:28:29.507876 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:29.507986 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:28:29.503212 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:28:29.503267 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:29.536160 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:28:29.536234 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:36.546710 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:36.702156 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:36.702190 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:36.702204 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:36.702288 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:36.702332 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:36.702343 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:36.709053 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:36.709133 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:28:36.736690 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:28:36.736753 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:37.842311 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:38.002026 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:38.002058 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:38.002073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:38.002140 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:38.002163 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:38.002171 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:38.008989 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:38.009090 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:28:38.038065 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:28:38.038129 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:28:38.723914 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:38.888275 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:38.888297 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:38.888313 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:38.888397 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:38.888431 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:38.888440 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:38.895148 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:38.895193 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:28:38.922973 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:28:38.923030 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:40.750430 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:40.907534 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:40.907569 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:40.907589 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:40.907671 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:40.907694 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:40.907702 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:40.915372 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:40.915425 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:28:40.943087 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:28:40.943149 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:45.797964 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:45.954300 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:45.954331 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:45.954349 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:45.954426 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:45.954477 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:45.954487 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:45.963540 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:45.963656 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:28:45.991821 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:28:45.991884 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:48.964913 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:49.120484 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:49.120515 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:49.120531 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:49.120623 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:49.120668 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:49.120679 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:49.128680 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:49.128733 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:28:49.156555 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:28:49.156617 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:50.695757 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:50.777164 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:50.844160 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:50.844193 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:50.844208 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:50.844314 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:50.844347 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:50.844357 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:50.852037 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:50.852148 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:28:50.879903 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:28:50.879959 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:50.932254 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:50.932287 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:50.932307 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:50.932386 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:50.932407 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:50.932414 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:50.939216 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:50.939264 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4a394cb9d0"
I1223 07:28:50.966810 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4a394cb9d0"
I1223 07:28:50.966874 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:51.138719 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:51.295050 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:51.295082 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:51.295097 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:51.295191 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:51.295226 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:51.295235 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:51.304065 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:51.304165 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:28:51.331957 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:28:51.332024 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:55.803840 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:55.959145 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:55.959178 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f4a54047b10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f4a540175a8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:55.959197 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:55.959271 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:55.959314 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:55.959323 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:55.966030 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:55.966113 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4979d9af70"
I1223 07:28:55.993167 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4979d9af70"
I1223 07:28:55.993220 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:57.527697 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:57.683358 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:57.683391 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:57.683406 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:57.683481 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:57.683504 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:57.683512 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:57.691266 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:57.691318 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:28:57.719240 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:28:57.719297 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:58.646285 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:58.802652 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:58.802684 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:58.802699 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:58.802780 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:58.802824 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:28:58.802834 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:28:58.810562 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:58.810671 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:28:58.838839 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:28:58.838910 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:28:59.093674 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:28:59.258036 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:28:59.258069 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:28:59.258088 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:28:59.258158 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:28:59.258179 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:28:59.258185 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:28:59.264891 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:28:59.264946 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:28:59.292905 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:28:59.292965 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:00.414330 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:00.560051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:00.560076 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:00.560090 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:00.560168 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:00.560351 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:00.560366 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:00.569292 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:00.569390 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:29:00.597130 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:29:00.597187 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:07.722131 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:07.881631 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:07.881667 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:07.881686 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:07.881750 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:07.881808 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:07.881893 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:07.889648 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:07.889712 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:29:07.918017 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:29:07.918090 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:08.171814 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:08.327539 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:08.327574 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:08.327592 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:08.327669 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:08.327693 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:08.327701 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:08.335799 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:08.335913 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:29:08.363855 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:29:08.363930 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:11.188220 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:11.332320 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:11.332353 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:11.332369 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:11.332440 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:11.332461 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:11.332469 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:11.341537 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:11.341653 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:29:11.369429 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:29:11.369494 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:13.715778 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:13.864081 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:13.864113 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:13.864133 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:13.864234 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:13.864270 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:13.864279 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:13.871879 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:13.871973 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:29:13.899632 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:29:13.899690 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:16.493961 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:16.613895 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:16.650067 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:16.650101 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:16.650120 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:16.650188 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:16.650231 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:16.650240 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:16.657813 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:16.657864 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:29:16.685588 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:29:16.685658 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:16.771255 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:16.771292 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:16.771307 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:16.771407 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:16.771472 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:16.771482 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:16.778312 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:16.778363 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:29:16.805919 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:29:16.805991 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:17.143171 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:17.298540 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:17.298569 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:17.298583 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:17.298664 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:17.298696 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:17.298704 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:17.305506 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:17.305554 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:29:17.333366 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:29:17.333431 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:19.879127 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:20.044122 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:20.044155 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:20.044171 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:20.044243 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:20.044262 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:20.044271 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:20.051008 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:20.051056 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:29:20.078775 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:29:20.078827 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:20.073638 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:20.229689 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:20.229725 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:20.229740 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:20.229815 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:20.229834 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:20.229844 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:20.238165 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:20.238269 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:29:20.266212 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:29:20.266287 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:21.362578 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:21.519613 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:21.519645 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:21.519664 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:21.519764 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:21.519823 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:21.519858 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:21.527826 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:21.527948 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:29:21.556176 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:29:21.556253 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:31.039248 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:31.194797 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:31.194833 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:31.194852 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:31.194925 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:31.194947 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:31.194956 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:31.201619 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:31.201672 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:29:31.202373 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:31.229193 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:29:31.229256 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:31.351074 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:31.351105 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:31.351120 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:31.351180 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:31.351201 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:31.351220 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:31.358815 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:31.358918 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:29:31.386667 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:29:31.386722 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:31.738408 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:31.894283 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:31.894318 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:31.894337 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:31.894410 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:31.894432 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:31.894440 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:31.901215 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:31.901261 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:29:31.928672 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:29:31.928728 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:33.740839 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:33.896574 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:33.896609 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:33.896626 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:33.896728 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:33.896762 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:33.896772 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:33.905745 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:33.905849 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:29:33.933709 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:29:33.933778 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:35.973142 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:36.137020 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:36.137052 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:36.137067 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:36.137143 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:36.137162 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:36.137171 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:36.143906 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:36.143951 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:29:36.171720 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:29:36.171776 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:38.095845 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:38.257330 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:38.257364 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:38.257383 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:38.257467 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:38.257513 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:38.257523 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:38.265229 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:38.265286 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:29:38.292882 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:29:38.292936 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:38.862505 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:39.018956 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:39.018992 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:39.019012 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:39.019089 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:39.019147 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:39.019157 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:39.026908 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:39.027014 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:29:39.055210 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:29:39.055284 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:41.154268 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:41.304915 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:41.304947 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:41.304967 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:41.305039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:41.305086 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:41.305097 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:41.312773 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:41.312865 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:29:41.340635 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:29:41.340685 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:44.629326 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:44.785703 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:44.785739 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:44.785758 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:44.785851 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:44.785874 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:44.785894 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:44.792685 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:44.792741 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:29:44.820429 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:29:44.820504 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:46.794702 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:46.958913 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:46.958949 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:46.958968 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:46.959039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:46.959057 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:46.959066 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:46.965847 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:46.965898 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:29:46.993686 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:29:46.993745 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:51.225517 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:51.253030 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:51.381842 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:51.381876 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:51.381891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:51.381975 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:51.382016 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:51.382024 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:51.390294 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:51.390410 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:29:51.401241 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:51.401271 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:51.401289 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:51.401398 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:51.401419 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:51.401427 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:51.418726 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:29:51.418800 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:51.409014 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:51.409122 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:29:51.436819 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:29:51.436870 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:56.425427 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:56.589414 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:56.589448 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:56.589467 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:56.589554 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:56.589579 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:29:56.589588 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:29:56.596343 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:56.596393 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:29:56.624257 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:29:56.624321 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:29:59.105037 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:29:59.261276 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:29:59.261312 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:29:59.261327 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:29:59.261421 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:29:59.261440 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:29:59.261448 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:29:59.268265 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:29:59.268319 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:29:59.296153 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:29:59.296213 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:02.676444 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:02.831838 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:02.831874 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:02.831894 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:02.831971 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:02.831992 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:02.832001 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:02.841079 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:02.841207 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:30:02.869317 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:30:02.869384 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:03.208744 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:03.356988 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:03.357023 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:03.357039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:03.357146 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:03.357181 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:03.357191 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:03.364880 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:03.364993 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:30:03.392974 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:30:03.393048 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:04.137990 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:04.292967 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:04.292998 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7e1cb0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:04.293014 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:04.293073 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:04.293095 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:04.293116 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:04.301203 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:04.301605 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54850bbc90"
I1223 07:30:04.329623 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54850bbc90"
I1223 07:30:04.329668 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:04.402205 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:04.558071 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:04.558108 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:04.558123 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:04.558270 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:04.558305 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:04.558315 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:04.566531 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:04.566638 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:30:04.594752 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:30:04.594823 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:06.139993 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:06.295167 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:06.295197 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:06.295212 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:06.295289 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:06.295324 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:06.295335 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:06.303014 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:06.303124 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:30:06.331306 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:30:06.331372 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:07.089714 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:07.253177 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:07.253211 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:07.253226 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:07.253328 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:07.253361 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:07.253370 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:07.260104 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:07.260154 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:30:07.288027 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:30:07.288083 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:11.564026 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:11.723272 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:11.723313 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:11.723330 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:11.723409 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:11.723448 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:11.723458 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:11.730320 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:11.730381 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:30:11.758030 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:30:11.758103 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:11.942850 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:12.096928 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:12.096961 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dd7e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:12.096978 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:12.097056 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:12.097076 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:12.097084 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:12.105984 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:12.106043 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555cf9de00"
I1223 07:30:12.115200 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:12.133746 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555cf9de00"
I1223 07:30:12.133791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:12.273168 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:12.273202 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:12.273219 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:12.273289 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:12.273311 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:12.273319 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:12.280807 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:12.280863 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:30:12.308498 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:30:12.308553 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:16.176386 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:16.332332 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:16.332362 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:16.332378 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:16.332459 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:16.332480 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:16.332488 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:16.341523 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:16.341633 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:30:16.369397 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:30:16.369451 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:17.428365 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:17.583308 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:17.583339 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dd7e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:17.583354 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:17.583428 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:17.583467 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:17.583478 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:17.591011 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:17.591116 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54850bbc90"
I1223 07:30:17.619127 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54850bbc90"
I1223 07:30:17.619171 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:25.619440 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:25.774745 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:25.774776 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dd7e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:25.774791 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:25.774874 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:25.774918 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:25.774928 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:25.783624 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:25.783680 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f555cf9de00"
I1223 07:30:25.811323 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f555cf9de00"
I1223 07:30:25.811367 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:27.269404 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:27.419017 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:27.419048 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:27.419063 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:27.419137 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:27.419173 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:27.419182 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:27.426847 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:27.426953 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:30:27.454759 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:30:27.454815 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:29.731371 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:29.886147 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:29.886175 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f557d7dd7e0] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f557c047578] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:29.886190 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:29.886272 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:29.886290 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:29.886313 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:29.893994 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:29.894092 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f54850bbc90"
I1223 07:30:29.922238 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f54850bbc90"
I1223 07:30:29.922279 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:31.053004 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:31.208782 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:31.208813 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:31.208833 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:31.208907 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:31.208930 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:31.208938 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:31.215677 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:31.215725 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:30:31.243358 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:30:31.243418 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:34.105799 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:34.270291 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:34.270323 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:34.270338 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:34.270420 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:34.270441 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:34.270449 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:34.277296 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:34.277356 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:30:34.305248 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:30:34.305310 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:34.641227 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:34.797156 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:34.797193 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:34.797212 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:34.797319 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:34.797399 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:34.797447 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:34.805627 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:34.805680 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:30:34.833631 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:30:34.833686 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:35.223668 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:35.380720 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:35.380757 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:35.380773 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:35.380845 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:35.380867 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:35.380878 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:35.389116 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:35.389246 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:30:35.417344 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:30:35.417411 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:35.492424 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:35.648070 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:35.648103 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:35.648117 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:35.648214 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:35.648248 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:35.648261 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:35.656013 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:35.656114 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:30:35.684100 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:30:35.684169 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:36.972094 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:37.118537 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:37.118573 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:37.118588 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:37.118676 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:37.118710 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:37.118719 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:37.127785 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:37.127898 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:30:37.156121 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:30:37.156188 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:39.286614 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:39.435307 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:39.435345 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:39.435366 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:39.435463 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:39.435486 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:39.435496 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:39.443274 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:39.443374 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:30:39.471132 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:30:39.471186 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:41.742892 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:41.899402 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:41.899451 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:41.899468 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:41.899585 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:41.899620 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:41.899630 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:41.906403 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:41.906459 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:30:41.934088 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:30:41.934162 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:30:49.248872 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:49.406614 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:49.406654 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:49.406670 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:49.406752 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:49.406799 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:49.406808 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:49.415020 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:49.415129 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:30:49.443232 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:30:49.443306 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:52.761788 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:52.925914 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:52.925947 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:52.925965 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:52.926045 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:52.926062 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:52.926071 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:52.932806 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:52.932860 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:30:52.960723 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:30:52.960781 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:56.489591 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"

I1223 07:30:56.637813 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:56.637849 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:56.637865 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:56.637959 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:56.637995 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:56.638006 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:56.645686 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:56.645782 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:30:56.673449 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:30:56.673509 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:57.218019 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:57.309349 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:57.374068 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:57.374106 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:57.374122 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:57.374206 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:57.374241 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:30:57.374249 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:30:57.382090 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:57.382156 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:30:57.410142 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:30:57.410205 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:57.465664 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:57.465698 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb4045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb404b878] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:57.465712 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:57.465797 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:57.465816 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:57.465824 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:57.472707 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:57.472765 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:30:57.500883 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:30:57.501044 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:30:59.279556 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:30:59.436868 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:30:59.436903 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:30:59.436919 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:30:59.436998 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:30:59.437037 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:30:59.437048 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:30:59.446393 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:30:59.446515 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:30:59.474741 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:30:59.474800 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:00.322883 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:00.469102 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:00.469138 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:00.469156 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:00.469232 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:00.469315 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:00.469343 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:00.477234 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:00.477290 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:31:00.505298 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:31:00.505363 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:02.225570 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:02.370019 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:02.370054 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:02.370069 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:02.370153 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:02.370187 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:02.370195 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:02.379104 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:02.379216 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f14bc6c2790"
I1223 07:31:02.406994 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f14bc6c2790"
I1223 07:31:02.407061 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:04.047502 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:04.203051 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:04.203085 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb4013288] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb4013288] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:04.203101 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:04.203177 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:04.203209 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:04.203220 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:04.211044 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:04.211168 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb9697370"
I1223 07:31:04.239388 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb9697370"
I1223 07:31:04.239459 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:04.649535 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:04.814032 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:04.814065 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:04.814085 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:04.814159 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:04.814179 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:04.814188 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:04.820981 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:04.821036 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:31:04.848828 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:31:04.848891 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:07.928811 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:08.085138 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:08.085171 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:08.085186 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:08.085268 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:08.085302 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:08.085312 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:08.091985 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:08.092031 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:31:08.119800 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:31:08.119865 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:10.067986 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:10.220003 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:10.220032 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:10.220049 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:10.220105 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:10.220123 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:10.220139 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:10.227862 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:10.227955 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:31:10.255718 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:31:10.255794 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:12.013816 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:12.169875 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:12.169910 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:12.169924 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:12.170012 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:12.170034 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:12.170042 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:12.178198 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:12.178303 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:31:12.206385 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:31:12.206453 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"

I1223 07:31:18.987636 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:19.153900 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:19.153935 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:19.153952 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:19.154039 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:19.154071 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:19.154080 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:19.160815 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:19.160870 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f4089765c30"
I1223 07:31:19.188687 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f4089765c30"
I1223 07:31:19.188755 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:20.104662 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:20.261437 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:20.261472 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:20.261489 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:20.261582 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:20.261626 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:20.261637 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:20.268424 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:20.268476 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2de95d2ea0"
I1223 07:31:20.296696 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2de95d2ea0"
I1223 07:31:20.296764 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:23.398853 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:23.555132 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:23.555178 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f15a4046800] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f15a4017238] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:23.555195 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:23.555298 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:23.555333 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:23.555343 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:23.563163 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:23.563216 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f1588e60700"
I1223 07:31:23.590908 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f1588e60700"
I1223 07:31:23.590980 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:23.960587 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:24.108641 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:24.108674 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f40b004dd10] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f40b00463e8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:24.108689 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:24.108759 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:24.108780 1 onnxruntime.cc:3135] "model screen, instance screen_0_0, executing 1 requests"
I1223 07:31:24.108788 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_0 with 1 requests"
I1223 07:31:24.116455 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:24.116546 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3fdaa91f40"
I1223 07:31:24.144276 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3fdaa91f40"
I1223 07:31:24.144325 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:26.170920 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:26.326803 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:26.326835 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f2e04045c80] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f2e0405d7b8] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:26.326855 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:26.326940 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:26.326960 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:26.326971 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:26.335072 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:26.335206 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f2d20537d50"
I1223 07:31:26.363331 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f2d20537d50"
I1223 07:31:26.363398 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"
I1223 07:31:26.421315 1 http_server.cc:4615] "HTTP request: 2 /v2/models/screen/infer"
I1223 07:31:26.579446 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to INITIALIZED"
I1223 07:31:26.579474 1 infer_request.cc:905] "[request id: <id_unknown>] prepared: [0x0x7f3fb400a650] request id: , model: screen, requested version: -1, actual version: 1, flags: 0x0, correlation id: 0, batch size: 1, priority: 0, timeout (us): 0\noriginal inputs:\n[0x0x7f3fb4013288] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noverride inputs:\ninputs:\n[0x0x7f3fb4013288] input: images, type: FP32, original shape: [1,3,640,640], batch + shape: [1,3,640,640], shape: [3,640,640]\noriginal requested outputs:\nrequested outputs:\noutput0\n"
I1223 07:31:26.579489 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from INITIALIZED to PENDING"
I1223 07:31:26.579578 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from PENDING to EXECUTING"
I1223 07:31:26.579610 1 onnxruntime.cc:3135] "model screen, instance screen_0_1, executing 1 requests"
I1223 07:31:26.579620 1 onnxruntime.cc:1889] "TRITONBACKEND_ModelExecute: Running screen_0_1 with 1 requests"
I1223 07:31:26.586359 1 infer_response.cc:193] "add response output: output: output0, type: FP32, shape: [1,6,8400]"
I1223 07:31:26.586406 1 http_server.cc:1296] "HTTP using buffer for: 'output0', size: 201600, addr: 0x7f3eb0b92c30"
I1223 07:31:26.614004 1 http_server.cc:1370] "HTTP release: size 201600, addr 0x7f3eb0b92c30"
I1223 07:31:26.614048 1 infer_request.cc:132] "[request id: <id_unknown>] Setting state from EXECUTING to RELEASED"